{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c109dd0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c4978",
   "metadata": {},
   "source": [
    "Adapted from:\n",
    "\n",
    "https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f035599",
   "metadata": {},
   "source": [
    "## Environmental Variables\n",
    "Environmental variables are a way to set the configuration parameters of a program without needing to hardcode them in.  \n",
    "This means that these parameters can be changed without needing to alter the source code itself. This makes it much easier to run other peoples code with your own parameters/credentials, or to make changes to the runtime environment of the program by just editing a file.\n",
    "\n",
    "We will be using .env files to store our environment veriables, since this will work regardless of operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16918ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:48.716716Z",
     "start_time": "2023-05-07T21:15:48.699713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "# Lets us load the environment variables from the .env file\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3894cd73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:48.732361Z",
     "start_time": "2023-05-07T21:15:48.717716Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Library that has a lot of operating system functions\n",
    "from os import getenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e291d3c-f1c8-458a-9443-3c4509b5cac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5efda36-4283-40a5-a3f3-665cc83f16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=getenv(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3864cbfc-5f11-4272-bb80-15798e15d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python_is_best'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff744393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:48.747364Z",
     "start_time": "2023-05-07T21:15:48.733361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load from the .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get the environmental variables\n",
    "APP_NAME = getenv('APP_NAME')\n",
    "APP_ID = getenv(\"APP_ID\")\n",
    "APP_SECRET = getenv(\"APP_SECRET\")\n",
    "USERNAME = getenv('REDDIT_USERNAME')\n",
    "PASSWORD = getenv('PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c528541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:48.762368Z",
     "start_time": "2023-05-07T21:15:48.748366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afshan123456'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that is loads correctly\n",
    "USERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa945e0-e3bc-47a5-a5cb-c79b47f55482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded\n"
     ]
    }
   ],
   "source": [
    "# Check that the variables all loaded\n",
    "if APP_NAME and APP_ID and APP_SECRET and USERNAME:\n",
    "    print(\"Credentials loaded\")\n",
    "else:\n",
    "    print(\"ERROR: Credentials not loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db01778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:48.777562Z",
     "start_time": "2023-05-07T21:15:48.763370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded\n"
     ]
    }
   ],
   "source": [
    "# Check that the variables all loaded\n",
    "if APP_NAME and APP_ID and APP_SECRET and USERNAME and PASSWORD:\n",
    "    print(\"Credentials loaded\")\n",
    "else:\n",
    "    print(\"ERROR: Credentials not loaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d91487be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:49.865143Z",
     "start_time": "2023-05-07T21:15:48.778564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Library that let's us make http requests\n",
    "import requests\n",
    "\n",
    "# Sets up the authentication part of the request\n",
    "auth = requests.auth.HTTPBasicAuth(f'{APP_ID}', f'{APP_SECRET}')\n",
    "\n",
    "# Sets up the data we want to send: our login method (password), username, and password\n",
    "data = {'grant_type': 'password',\n",
    "        'username': f'{USERNAME}',\n",
    "        'password': f'{PASSWORD}'}\n",
    "\n",
    "# Sets up this requests header info, which gives reddit a brief description of our app\n",
    "# This is the format requested by Reddit: os:app_name:version (by /u/username)\n",
    "headers = {'User-Agent': f'windows:{APP_NAME}:v1.0 (by /u/{USERNAME})'}\n",
    "\n",
    "# Makes the request to the access_token api endpoint, and saves the response in res\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "# Converts response to JSON and pull access_token value\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "# Adds authorisation to our headers dictionary\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# While the token is valid (~2 hours) we can just add headers=headers to our requests to prove authentication\n",
    "# Making a test request. <Response [200]> means that it was a success!\n",
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91f9d6b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:50.531623Z",
     "start_time": "2023-05-07T21:15:49.866142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'Listing', 'data': {'after': 't3_1k5c8dk', 'dist': 27, 'modhash': None, 'geo_filter': None, 'children': [{'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è\\n\\nHello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!\\n\\n## How it Works:\\n\\n1. **Show &amp; Tell**: Share your current projects, completed works, or future ideas.\\n2. **Discuss**: Get feedback, find collaborators, or just chat about your project.\\n3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.\\n\\n## Guidelines:\\n\\n* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.\\n* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.\\n\\n## Example Shares:\\n\\n1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!\\n2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.\\n3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!\\n\\nLet's build and grow together! Share your journey and learn from others. Happy coding! üåü\", 'author_fullname': 't2_6l4z3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"Sunday Daily Thread: What's everyone working on this week?\", 'link_flair_richtext': [{'a': ':pythonLogo:', 'e': 'emoji', 'u': 'https://emoji.redditmedia.com/8yxdpg6xxnr71_t5_2qh0y/pythonLogo'}, {'e': 'text', 't': ' Daily Thread'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'daily-thread', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k39vt8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.57, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': ':pythonLogo: Daily Thread', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745107233.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Weekly Thread: What&amp;#39;s Everyone Working On This Week? üõ†Ô∏è&lt;/h1&gt;\\n\\n&lt;p&gt;Hello &lt;a href=\"/r/Python\"&gt;/r/Python&lt;/a&gt;! It&amp;#39;s time to share what you&amp;#39;ve been working on! Whether it&amp;#39;s a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you&amp;#39;re up to!&lt;/p&gt;\\n\\n&lt;h2&gt;How it Works:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Show &amp;amp; Tell&lt;/strong&gt;: Share your current projects, completed works, or future ideas.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Discuss&lt;/strong&gt;: Get feedback, find collaborators, or just chat about your project.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Inspire&lt;/strong&gt;: Your project might inspire someone else, just as you might get inspired here.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;h2&gt;Guidelines:&lt;/h2&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Feel free to include as many details as you&amp;#39;d like. Code snippets, screenshots, and links are all welcome.&lt;/li&gt;\\n&lt;li&gt;Whether it&amp;#39;s your job, your hobby, or your passion project, all Python-related work is welcome here.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h2&gt;Example Shares:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Machine Learning Model&lt;/strong&gt;: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Web Scraping&lt;/strong&gt;: Built a script to scrape and analyze news articles. It&amp;#39;s helped me understand media bias better.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Automation&lt;/strong&gt;: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Let&amp;#39;s build and grow together! Share your journey and learn from others. Happy coding! üåü&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '6c024934-de3f-11ea-a05a-0ea86b2be9a1', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': 'moderator', 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#00a6a5', 'id': '1k39vt8', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 0, 'send_replies': False, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k39vt8/sunday_daily_thread_whats_everyone_working_on/', 'stickied': True, 'url': 'https://www.reddit.com/r/Python/comments/1k39vt8/sunday_daily_thread_whats_everyone_working_on/', 'subreddit_subscribers': 1349732, 'created_utc': 1745107233.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"# Weekly Thread: Professional Use, Jobs, and Education üè¢\\n\\nWelcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.\\n\\n---\\n\\n## How it Works:\\n\\n1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.\\n2. **Education Q&amp;A**: Ask or answer questions about Python courses, certifications, and educational resources.\\n3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.\\n\\n---\\n\\n## Guidelines:\\n\\n- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.\\n- Keep discussions relevant to Python in the professional and educational context.\\n  \\n---\\n\\n## Example Topics:\\n\\n1. **Career Paths**: What kinds of roles are out there for Python developers?\\n2. **Certifications**: Are Python certifications worth it?\\n3. **Course Recommendations**: Any good advanced Python courses to recommend?\\n4. **Workplace Tools**: What Python libraries are indispensable in your professional work?\\n5. **Interview Tips**: What types of Python questions are commonly asked in interviews?\\n\\n---\\n\\nLet's help each other grow in our careers and education. Happy discussing! üåü\", 'author_fullname': 't2_6l4z3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Thursday Daily Thread: Python Careers, Courses, and Furthering Education!', 'link_flair_richtext': [{'a': ':pythonLogo:', 'e': 'emoji', 'u': 'https://emoji.redditmedia.com/8yxdpg6xxnr71_t5_2qh0y/pythonLogo'}, {'e': 'text', 't': ' Daily Thread'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'daily-thread', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6ecup', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': ':pythonLogo: Daily Thread', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745452830.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Weekly Thread: Professional Use, Jobs, and Education üè¢&lt;/h1&gt;\\n\\n&lt;p&gt;Welcome to this week&amp;#39;s discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is &lt;strong&gt;not for recruitment&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;h2&gt;How it Works:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Career Talk&lt;/strong&gt;: Discuss using Python in your job, or the job market for Python roles.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Education Q&amp;amp;A&lt;/strong&gt;: Ask or answer questions about Python courses, certifications, and educational resources.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Workplace Chat&lt;/strong&gt;: Share your experiences, challenges, or success stories about using Python professionally.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;h2&gt;Guidelines:&lt;/h2&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;This thread is &lt;strong&gt;not for recruitment&lt;/strong&gt;. For job postings, please see &lt;a href=\"/r/PythonJobs\"&gt;r/PythonJobs&lt;/a&gt; or the recruitment thread in the sidebar.&lt;/li&gt;\\n&lt;li&gt;Keep discussions relevant to Python in the professional and educational context.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;h2&gt;Example Topics:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Career Paths&lt;/strong&gt;: What kinds of roles are out there for Python developers?&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Certifications&lt;/strong&gt;: Are Python certifications worth it?&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Course Recommendations&lt;/strong&gt;: Any good advanced Python courses to recommend?&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Workplace Tools&lt;/strong&gt;: What Python libraries are indispensable in your professional work?&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Interview Tips&lt;/strong&gt;: What types of Python questions are commonly asked in interviews?&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;hr/&gt;\\n\\n&lt;p&gt;Let&amp;#39;s help each other grow in our careers and education. Happy discussing! üåü&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '6c024934-de3f-11ea-a05a-0ea86b2be9a1', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': 'moderator', 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#00a6a5', 'id': '1k6ecup', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 0, 'send_replies': False, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6ecup/thursday_daily_thread_python_careers_courses_and/', 'stickied': True, 'url': 'https://www.reddit.com/r/Python/comments/1k6ecup/thursday_daily_thread_python_careers_courses_and/', 'subreddit_subscribers': 1349732, 'created_utc': 1745452830.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'Long story short, mr big bollocks has been hired for a few months and he‚Äôs causing chaos and carnage but as with all things corporate, the powers that be aren‚Äôt listening. \\n\\nFirst of many battles I need to fight is pushing for a proper static code analysis tool to be implemented in our processes. However, the new fancy big pay check consultant is arguing against it. \\n\\nAnyone got any ideas or anecdotes for me to include in my arguement that will help strengthen my case? Currently, the plan is to just push stuff live with minimal code reviews as ‚Äúthe new process eliminates the need for additional tools and reduces time spent deliberatating completed activities‚Äù \\n\\nIn other words, we‚Äôre heading down a route of ‚Äújust ship it and pray it doesn‚Äôt break something‚Äù ', 'author_fullname': 't2_kodoi869', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Dealing with internal chaos due to a new ‚Äúcode efficiency consultant‚Äù that‚Äôs been hired.', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6nfef', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.98, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 102, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 102, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745484475.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short, mr big bollocks has been hired for a few months and he‚Äôs causing chaos and carnage but as with all things corporate, the powers that be aren‚Äôt listening. &lt;/p&gt;\\n\\n&lt;p&gt;First of many battles I need to fight is pushing for a proper static code analysis tool to be implemented in our processes. However, the new fancy big pay check consultant is arguing against it. &lt;/p&gt;\\n\\n&lt;p&gt;Anyone got any ideas or anecdotes for me to include in my arguement that will help strengthen my case? Currently, the plan is to just push stuff live with minimal code reviews as ‚Äúthe new process eliminates the need for additional tools and reduces time spent deliberatating completed activities‚Äù &lt;/p&gt;\\n\\n&lt;p&gt;In other words, we‚Äôre heading down a route of ‚Äújust ship it and pray it doesn‚Äôt break something‚Äù &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k6nfef', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'LonelyArmpit', 'discussion_type': None, 'num_comments': 44, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6nfef/dealing_with_internal_chaos_due_to_a_new_code/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6nfef/dealing_with_internal_chaos_due_to_a_new_code/', 'subreddit_subscribers': 1349732, 'created_utc': 1745484475.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'For this animation I used manim and Euler integration method (with a step of step=0.004 over 10000 iterations) for the ODEs of the Lorenz system \\n\\nLorenz Attractor 3D Animation\\xa0|\\xa0Chaos Theory Visualized\\nhttps://youtu.be/EmwGZE5MVLQ', 'author_fullname': 't2_c5wzpfbj', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Visualizing the Lorenz attractor with Python', 'link_flair_richtext': [{'e': 'text', 't': 'Resource'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'resource', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6pii4', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 11, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Resource', 'can_mod_post': False, 'score': 11, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745492967.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For this animation I used manim and Euler integration method (with a step of step=0.004 over 10000 iterations) for the ODEs of the Lorenz system &lt;/p&gt;\\n\\n&lt;p&gt;Lorenz Attractor 3D Animation\\xa0|\\xa0Chaos Theory Visualized\\n&lt;a href=\"https://youtu.be/EmwGZE5MVLQ\"&gt;https://youtu.be/EmwGZE5MVLQ&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/QzQyQve7Nj7rLRHPIYmWi6veimplxizLFozYdOdwBVs.jpg?auto=webp&amp;s=85de07587e502c776ef3a5be78d819b98b13ac44', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/QzQyQve7Nj7rLRHPIYmWi6veimplxizLFozYdOdwBVs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d013cfc018ae2e0987cd379205debbfe4e8c2d0f', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/QzQyQve7Nj7rLRHPIYmWi6veimplxizLFozYdOdwBVs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c39fdcb00fb2cadce7ad0fb7c5a1c50235c2f3ff', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/QzQyQve7Nj7rLRHPIYmWi6veimplxizLFozYdOdwBVs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c8a68d12b93612c9f1fcc1f2d4da3419a9a3ad02', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'IMsoHREFJ5VkM65m3gJeP6zk7wnXpYmn7WsBABs0We8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f9716fb2-4113-11ea-a3f1-0ef51f60f757', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ddbd37', 'id': '1k6pii4', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'EvanMaths', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6pii4/visualizing_the_lorenz_attractor_with_python/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6pii4/visualizing_the_lorenz_attractor_with_python/', 'subreddit_subscribers': 1349732, 'created_utc': 1745492967.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'I am thinking of Polars to utilize the multi-core support. But I wonder if Polars is compatible with other packages in the PyData stack, such as scikit-learn and XGboost?', 'author_fullname': 't2_57j4x5fp', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Polars: what is the status of compatibility with other Python packages?', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6ppc7', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.77, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745493633.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking of Polars to utilize the multi-core support. But I wonder if Polars is compatible with other packages in the PyData stack, such as scikit-learn and XGboost?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k6ppc7', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'AMGraduate564', 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6ppc7/polars_what_is_the_status_of_compatibility_with/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6ppc7/polars_what_is_the_status_of_compatibility_with/', 'subreddit_subscribers': 1349732, 'created_utc': 1745493633.0, 'num_crossposts': 1, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'Yo!\\n\\nThis is a tool that was proposed by someone over here at\\xa0[r/opensource](https://www.reddit.com/r/opensource/). Can\\'t remember who it was but anyways, I started on v0.0.1 about 2 months ago or so and for the last month been working on v0.0.2. So to briefly introduce Jonq, its a tool that lets you query JSON data using SQLish/Pythonic-like syntax.\\n\\n# Why I built this\\n\\nI love\\xa0`jq`, but every time I need to use it, my head literally spins. So since a good person recommended we try write a wrapper around jq, I thought, sure why not.\\n\\n# What my project does?\\n\\n`jonq`\\xa0is essentially a Python wrapper around\\xa0`jq`\\xa0that translates familiar SQL-like syntax into\\xa0`jq`\\xa0filters. The idea is simple:\\n\\n    bash\\n    jonq data.json \"select name, age if age &gt; 30 sort age desc\"\\n\\nInstead of:\\n\\n    bash\\n    jq \\'.[] | select(.age &gt; 30) | {name, age}\\' data.json | jq \\'sort_by(.age) | reverse\\'\\n\\n# Features\\n\\n* **SQL-like syntax**:\\xa0`select`,\\xa0`if`,\\xa0`sort`,\\xa0`group by`, etc.\\n* **Aggregations**:\\xa0`sum`,\\xa0`avg`,\\xa0`count`,\\xa0`max`,\\xa0`min`\\n* **Nested data**: Dot notation for nested fields, bracket notation for arrays\\n* **Export formats**: Output as JSON (default) or CSV (previously CSV wasn\\'t an option)\\n\\n# Target Audience\\n\\nAnyone who works with json \\n\\n# Comparison \\n\\nDuckdb, Pandas\\n\\n# Examples\\n\\n# Basic filtering:\\n\\n    ## Get names and emails of users if active\\n    jonq users.json \"select name, email if active = true\"\\n\\n# Nested data:\\n\\n    ## Get order items from each user\\'s orders\\n    jonq data.json \"select user.name, order.item from [].orders\"\\n\\n# Aggregations &amp; Grouping:\\n\\n    ## Average age by city\\n    jonq users.json \"select city, avg(age) as avg_age group by city\"\\n\\n# More complex queries\\n\\n    ## Top 3 cities by total order value\\n    jonq data.json \"select \\n      city, \\n      sum(orders.price) as total_value \\n      group by city \\n      having count(*) &gt; 5 \\n      sort total_value desc \\n      3\"\\n\\n# Installation\\n\\n    pip install jonq\\n\\n(Requires Python 3.8+ and please ensure that\\xa0`jq`\\xa0is installed on your system)\\n\\nAnd if you want a faster option to flatten your json we have:\\n\\n    pip install jonq-fast\\n\\nIt is essentially a rust wrapper.\\n\\n# Why Jonq over like pandas or duckdb?\\n\\nWe are lightweight, more memory efficient, leveraging jq\\'s power. Everything else PLEASE REFER TO THE DOCS OR README.\\n\\n# What\\'s next?\\n\\nI\\'ve got a few ideas for the next version:\\n\\n* Better handling of date/time fields\\n* Multiple file support (UNION, JOIN)\\n* Custom function definitions\\n\\nGithub link:\\xa0[https://github.com/duriantaco/jonq](https://github.com/duriantaco/jonq)\\n\\nDocs:\\xa0[https://jonq.readthedocs.io/en/latest/](https://jonq.readthedocs.io/en/latest/)\\n\\nLet me know what you guys think, looking for feedback, and if you want to contribute, ping me here! If you find it useful, please leave star, like share and subscribe LOL. if you want to bash me, think its a stupid idea, want to let off some steam yada yada, also do feel free to do so here. That\\'s all I have for yall folks. Thanks for reading.', 'author_fullname': 't2_618pjzkm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Jonq! Your python wrapper for jq thats readable', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6es7d', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 27, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 27, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745454082.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yo!&lt;/p&gt;\\n\\n&lt;p&gt;This is a tool that was proposed by someone over here at\\xa0&lt;a href=\"https://www.reddit.com/r/opensource/\"&gt;r/opensource&lt;/a&gt;. Can&amp;#39;t remember who it was but anyways, I started on v0.0.1 about 2 months ago or so and for the last month been working on v0.0.2. So to briefly introduce Jonq, its a tool that lets you query JSON data using SQLish/Pythonic-like syntax.&lt;/p&gt;\\n\\n&lt;h1&gt;Why I built this&lt;/h1&gt;\\n\\n&lt;p&gt;I love\\xa0&lt;code&gt;jq&lt;/code&gt;, but every time I need to use it, my head literally spins. So since a good person recommended we try write a wrapper around jq, I thought, sure why not.&lt;/p&gt;\\n\\n&lt;h1&gt;What my project does?&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;code&gt;jonq&lt;/code&gt;\\xa0is essentially a Python wrapper around\\xa0&lt;code&gt;jq&lt;/code&gt;\\xa0that translates familiar SQL-like syntax into\\xa0&lt;code&gt;jq&lt;/code&gt;\\xa0filters. The idea is simple:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;bash\\njonq data.json &amp;quot;select name, age if age &amp;gt; 30 sort age desc&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;Instead of:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;bash\\njq &amp;#39;.[] | select(.age &amp;gt; 30) | {name, age}&amp;#39; data.json | jq &amp;#39;sort_by(.age) | reverse&amp;#39;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;h1&gt;Features&lt;/h1&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;SQL-like syntax&lt;/strong&gt;:\\xa0&lt;code&gt;select&lt;/code&gt;,\\xa0&lt;code&gt;if&lt;/code&gt;,\\xa0&lt;code&gt;sort&lt;/code&gt;,\\xa0&lt;code&gt;group by&lt;/code&gt;, etc.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Aggregations&lt;/strong&gt;:\\xa0&lt;code&gt;sum&lt;/code&gt;,\\xa0&lt;code&gt;avg&lt;/code&gt;,\\xa0&lt;code&gt;count&lt;/code&gt;,\\xa0&lt;code&gt;max&lt;/code&gt;,\\xa0&lt;code&gt;min&lt;/code&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Nested data&lt;/strong&gt;: Dot notation for nested fields, bracket notation for arrays&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Export formats&lt;/strong&gt;: Output as JSON (default) or CSV (previously CSV wasn&amp;#39;t an option)&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;Target Audience&lt;/h1&gt;\\n\\n&lt;p&gt;Anyone who works with json &lt;/p&gt;\\n\\n&lt;h1&gt;Comparison&lt;/h1&gt;\\n\\n&lt;p&gt;Duckdb, Pandas&lt;/p&gt;\\n\\n&lt;h1&gt;Examples&lt;/h1&gt;\\n\\n&lt;h1&gt;Basic filtering:&lt;/h1&gt;\\n\\n&lt;pre&gt;&lt;code&gt;## Get names and emails of users if active\\njonq users.json &amp;quot;select name, email if active = true&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;h1&gt;Nested data:&lt;/h1&gt;\\n\\n&lt;pre&gt;&lt;code&gt;## Get order items from each user&amp;#39;s orders\\njonq data.json &amp;quot;select user.name, order.item from [].orders&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;h1&gt;Aggregations &amp;amp; Grouping:&lt;/h1&gt;\\n\\n&lt;pre&gt;&lt;code&gt;## Average age by city\\njonq users.json &amp;quot;select city, avg(age) as avg_age group by city&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;h1&gt;More complex queries&lt;/h1&gt;\\n\\n&lt;pre&gt;&lt;code&gt;## Top 3 cities by total order value\\njonq data.json &amp;quot;select \\n  city, \\n  sum(orders.price) as total_value \\n  group by city \\n  having count(*) &amp;gt; 5 \\n  sort total_value desc \\n  3&amp;quot;\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;h1&gt;Installation&lt;/h1&gt;\\n\\n&lt;pre&gt;&lt;code&gt;pip install jonq\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;(Requires Python 3.8+ and please ensure that\\xa0&lt;code&gt;jq&lt;/code&gt;\\xa0is installed on your system)&lt;/p&gt;\\n\\n&lt;p&gt;And if you want a faster option to flatten your json we have:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;pip install jonq-fast\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;It is essentially a rust wrapper.&lt;/p&gt;\\n\\n&lt;h1&gt;Why Jonq over like pandas or duckdb?&lt;/h1&gt;\\n\\n&lt;p&gt;We are lightweight, more memory efficient, leveraging jq&amp;#39;s power. Everything else PLEASE REFER TO THE DOCS OR README.&lt;/p&gt;\\n\\n&lt;h1&gt;What&amp;#39;s next?&lt;/h1&gt;\\n\\n&lt;p&gt;I&amp;#39;ve got a few ideas for the next version:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Better handling of date/time fields&lt;/li&gt;\\n&lt;li&gt;Multiple file support (UNION, JOIN)&lt;/li&gt;\\n&lt;li&gt;Custom function definitions&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Github link:\\xa0&lt;a href=\"https://github.com/duriantaco/jonq\"&gt;https://github.com/duriantaco/jonq&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Docs:\\xa0&lt;a href=\"https://jonq.readthedocs.io/en/latest/\"&gt;https://jonq.readthedocs.io/en/latest/&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Let me know what you guys think, looking for feedback, and if you want to contribute, ping me here! If you find it useful, please leave star, like share and subscribe LOL. if you want to bash me, think its a stupid idea, want to let off some steam yada yada, also do feel free to do so here. That&amp;#39;s all I have for yall folks. Thanks for reading.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?auto=webp&amp;s=fa3d2aea70751381fd44066a41a60cf5378f63c4', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8eae1d5b6a52263b43c2740ea3196dd2ee649fff', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0ff677be3ed45f55247cc1df34edf7ec2095e7e', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=16d593f498db3a5410e0f33b19ef49d045bb1786', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff6a7d39e4a91086a5d7052b8867ee0a2739fd66', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=88f159ce83c31252b0932c36b71e26a8a1ae552e', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/UlzQ2LnQIi0fdVYpOrtiv-Qz-5r1FguI6pMQI-axa2A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d45c295436715680eb3dc5c243f4acd23cc025df', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'GYFkXPA6t3dePZ--h1M3umc_ychc-5y5rEwZvWNWx6s'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k6es7d', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'papersashimi', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6es7d/jonq_your_python_wrapper_for_jq_thats_readable/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6es7d/jonq_your_python_wrapper_for_jq_thats_readable/', 'subreddit_subscribers': 1349732, 'created_utc': 1745454082.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'Hey r/python,\\n\\nFollowing up on my previous posts about [`reaktiv`](https://github.com/buiapp/reaktiv) (my little reactive state library for Python/asyncio), I\\'ve added a few tools often seen in frontend, but surprisingly useful on the backend too: `filter`, `debounce`, `throttle`, and `pairwise`.\\n\\nWhile debouncing/throttling is common for UI events, backend systems often deal with similar patterns:\\n\\n* Handling bursts of events from IoT devices or sensors.\\n* Rate-limiting outgoing API calls triggered by internal state changes.\\n* Debouncing database writes after rapid updates to related data.\\n* Filtering noisy data streams before processing.\\n* Comparing consecutive values for trend detection and change analysis.\\n\\nManually implementing this logic usually involves `asyncio.sleep()`, `call_later`, managing timer handles, and tracking state; boilerplate that\\'s easy to get wrong, especially with concurrency.\\n\\nThe idea with `reaktiv` is to make this declarative. Instead of writing the timing logic yourself, you wrap a signal with these operators.\\n\\nHere\\'s a quick look at all the operators in action (simulating a sensor monitoring system):\\n\\n    import asyncio\\n    import random\\n    from reaktiv import signal, effect\\n    from reaktiv.operators import filter_signal, throttle_signal, debounce_signal, pairwise_signal\\n    \\n    # Simulate a sensor sending frequent temperature updates\\n    raw_sensor_reading = signal(20.0)\\n    \\n    async def main():\\n        # Filter: Only process readings within a valid range (15.0-30.0¬∞C)\\n        valid_readings = filter_signal(\\n            raw_sensor_reading, \\n            lambda temp: 15.0 &lt;= temp &lt;= 30.0\\n        )\\n        \\n        # Throttle: Process at most once every 2 seconds (trailing edge)\\n        throttled_reading = throttle_signal(\\n            valid_readings,\\n            interval_seconds=2.0,\\n            leading=False,  # Don\\'t process immediately \\n            trailing=True   # Process the last value after the interval\\n        )\\n        \\n        # Debounce: Only record to database after readings stabilize (500ms)\\n        db_reading = debounce_signal(\\n            valid_readings,\\n            delay_seconds=0.5\\n        )\\n        \\n        # Pairwise: Analyze consecutive readings to detect significant changes\\n        temp_changes = pairwise_signal(valid_readings)\\n    \\n        # Effect to \"process\" the throttled reading (e.g., send to dashboard)\\n        async def process_reading():\\n            if throttled_reading() is None:\\n                return\\n            temp = throttled_reading()\\n            print(f\"DASHBOARD: {temp:.2f}¬∞C (throttled)\")\\n    \\n        # Effect to save stable readings to database\\n        async def save_to_db():\\n            if db_reading() is None:\\n                return\\n            temp = db_reading()\\n            print(f\"DB WRITE: {temp:.2f}¬∞C (debounced)\")\\n    \\n        # Effect to analyze temperature trends\\n        async def analyze_trends():\\n            pair = temp_changes()\\n            if not pair:\\n                return\\n            prev, curr = pair\\n            delta = curr - prev\\n            if abs(delta) &gt; 2.0:\\n                print(f\"TREND ALERT: {prev:.2f}¬∞C ‚Üí {curr:.2f}¬∞C (Œî{delta:.2f}¬∞C)\")\\n    \\n        # Keep references to prevent garbage collection\\n        process_effect = effect(process_reading)\\n        db_effect = effect(save_to_db)\\n        trend_effect = effect(analyze_trends)\\n    \\n        async def simulate_sensor():\\n            print(\"Simulating sensor readings...\")\\n            for i in range(10):\\n                new_temp = 20.0 + random.uniform(-8.0, 8.0) * (i % 3 + 1) / 3\\n                raw_sensor_reading.set(new_temp)\\n                print(f\"Raw sensor: {new_temp:.2f}¬∞C\" + \\n                    (\" (out of range)\" if not (15.0 &lt;= new_temp &lt;= 30.0) else \"\"))\\n                await asyncio.sleep(0.3)  # Sensor sends data every 300ms\\n    \\n            print(\"...waiting for final intervals...\")\\n            await asyncio.sleep(2.5)\\n            print(\"Done.\")\\n    \\n        await simulate_sensor()\\n    \\n    asyncio.run(main())\\n    # Sample output (values will vary):\\n    # Simulating sensor readings...\\n    # Raw sensor: 19.16¬∞C\\n    # Raw sensor: 22.45¬∞C\\n    # TREND ALERT: 19.16¬∞C ‚Üí 22.45¬∞C (Œî3.29¬∞C)\\n    # Raw sensor: 17.90¬∞C\\n    # DB WRITE: 22.45¬∞C (debounced)\\n    # TREND ALERT: 22.45¬∞C ‚Üí 17.90¬∞C (Œî-4.55¬∞C)\\n    # Raw sensor: 24.32¬∞C\\n    # DASHBOARD: 24.32¬∞C (throttled)\\n    # DB WRITE: 17.90¬∞C (debounced)\\n    # TREND ALERT: 17.90¬∞C ‚Üí 24.32¬∞C (Œî6.42¬∞C)\\n    # Raw sensor: 12.67¬∞C (out of range)\\n    # Raw sensor: 26.84¬∞C\\n    # DB WRITE: 24.32¬∞C (debounced)\\n    # DB WRITE: 26.84¬∞C (debounced)\\n    # TREND ALERT: 24.32¬∞C ‚Üí 26.84¬∞C (Œî2.52¬∞C)\\n    # Raw sensor: 16.52¬∞C\\n    # DASHBOARD: 26.84¬∞C (throttled)\\n    # TREND ALERT: 26.84¬∞C ‚Üí 16.52¬∞C (Œî-10.32¬∞C)\\n    # Raw sensor: 31.48¬∞C (out of range)\\n    # Raw sensor: 14.23¬∞C (out of range)\\n    # Raw sensor: 28.91¬∞C\\n    # DB WRITE: 16.52¬∞C (debounced)\\n    # DB WRITE: 28.91¬∞C (debounced)\\n    # TREND ALERT: 16.52¬∞C ‚Üí 28.91¬∞C (Œî12.39¬∞C)\\n    # ...waiting for final intervals...\\n    # DASHBOARD: 28.91¬∞C (throttled)\\n    # Done.\\n\\nWhat this helps with on the **backend**:\\n\\n* **Filtering:** Ignore noisy sensor readings outside a valid range, skip processing events that don\\'t meet certain criteria before hitting a database or external API.\\n* **Debouncing:** Consolidate rapid updates before writing to a database (e.g., update user profile only after they\\'ve stopped changing fields for 500ms), trigger expensive computations only after a burst of related events settles.\\n* **Throttling:** Limit the rate of outgoing notifications (email, Slack) triggered by frequent internal events, control the frequency of logging for high-volume operations, enforce API rate limits for external services called reactively.\\n* **Pairwise:** Track trends by comparing consecutive values (e.g., monitoring temperature changes, detecting price movements, calculating deltas between readings), invaluable for anomaly detection and temporal analysis of data streams.\\n* Keeps the timing logic encapsulated within the operator, not scattered in your application code.\\n* Works naturally with `asyncio` for the time-based operators.\\n\\nThese are implemented using the same underlying `Effect` mechanism within `reaktiv`, so they integrate seamlessly with `Signal` and `ComputeSignal`.\\n\\nAvailable on PyPI (`pip install reaktiv`). The code is in the `reaktiv.operators` module.\\n\\nHow do you typically handle these kinds of event stream manipulations (filtering, rate-limiting, debouncing) in your backend Python services? Still curious about robust patterns people use for managing complex, time-sensitive state changes.', 'author_fullname': 't2_87rta9kt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Taming async events: Backend uses for pairwise, filter, debounce, throttle in `reaktiv`', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'tutorial', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1k6relk', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745499049.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/python\"&gt;r/python&lt;/a&gt;,&lt;/p&gt;\\n\\n&lt;p&gt;Following up on my previous posts about &lt;a href=\"https://github.com/buiapp/reaktiv\"&gt;&lt;code&gt;reaktiv&lt;/code&gt;&lt;/a&gt; (my little reactive state library for Python/asyncio), I&amp;#39;ve added a few tools often seen in frontend, but surprisingly useful on the backend too: &lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;debounce&lt;/code&gt;, &lt;code&gt;throttle&lt;/code&gt;, and &lt;code&gt;pairwise&lt;/code&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;While debouncing/throttling is common for UI events, backend systems often deal with similar patterns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Handling bursts of events from IoT devices or sensors.&lt;/li&gt;\\n&lt;li&gt;Rate-limiting outgoing API calls triggered by internal state changes.&lt;/li&gt;\\n&lt;li&gt;Debouncing database writes after rapid updates to related data.&lt;/li&gt;\\n&lt;li&gt;Filtering noisy data streams before processing.&lt;/li&gt;\\n&lt;li&gt;Comparing consecutive values for trend detection and change analysis.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Manually implementing this logic usually involves &lt;code&gt;asyncio.sleep()&lt;/code&gt;, &lt;code&gt;call_later&lt;/code&gt;, managing timer handles, and tracking state; boilerplate that&amp;#39;s easy to get wrong, especially with concurrency.&lt;/p&gt;\\n\\n&lt;p&gt;The idea with &lt;code&gt;reaktiv&lt;/code&gt; is to make this declarative. Instead of writing the timing logic yourself, you wrap a signal with these operators.&lt;/p&gt;\\n\\n&lt;p&gt;Here&amp;#39;s a quick look at all the operators in action (simulating a sensor monitoring system):&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;import asyncio\\nimport random\\nfrom reaktiv import signal, effect\\nfrom reaktiv.operators import filter_signal, throttle_signal, debounce_signal, pairwise_signal\\n\\n# Simulate a sensor sending frequent temperature updates\\nraw_sensor_reading = signal(20.0)\\n\\nasync def main():\\n    # Filter: Only process readings within a valid range (15.0-30.0¬∞C)\\n    valid_readings = filter_signal(\\n        raw_sensor_reading, \\n        lambda temp: 15.0 &amp;lt;= temp &amp;lt;= 30.0\\n    )\\n\\n    # Throttle: Process at most once every 2 seconds (trailing edge)\\n    throttled_reading = throttle_signal(\\n        valid_readings,\\n        interval_seconds=2.0,\\n        leading=False,  # Don&amp;#39;t process immediately \\n        trailing=True   # Process the last value after the interval\\n    )\\n\\n    # Debounce: Only record to database after readings stabilize (500ms)\\n    db_reading = debounce_signal(\\n        valid_readings,\\n        delay_seconds=0.5\\n    )\\n\\n    # Pairwise: Analyze consecutive readings to detect significant changes\\n    temp_changes = pairwise_signal(valid_readings)\\n\\n    # Effect to &amp;quot;process&amp;quot; the throttled reading (e.g., send to dashboard)\\n    async def process_reading():\\n        if throttled_reading() is None:\\n            return\\n        temp = throttled_reading()\\n        print(f&amp;quot;DASHBOARD: {temp:.2f}¬∞C (throttled)&amp;quot;)\\n\\n    # Effect to save stable readings to database\\n    async def save_to_db():\\n        if db_reading() is None:\\n            return\\n        temp = db_reading()\\n        print(f&amp;quot;DB WRITE: {temp:.2f}¬∞C (debounced)&amp;quot;)\\n\\n    # Effect to analyze temperature trends\\n    async def analyze_trends():\\n        pair = temp_changes()\\n        if not pair:\\n            return\\n        prev, curr = pair\\n        delta = curr - prev\\n        if abs(delta) &amp;gt; 2.0:\\n            print(f&amp;quot;TREND ALERT: {prev:.2f}¬∞C ‚Üí {curr:.2f}¬∞C (Œî{delta:.2f}¬∞C)&amp;quot;)\\n\\n    # Keep references to prevent garbage collection\\n    process_effect = effect(process_reading)\\n    db_effect = effect(save_to_db)\\n    trend_effect = effect(analyze_trends)\\n\\n    async def simulate_sensor():\\n        print(&amp;quot;Simulating sensor readings...&amp;quot;)\\n        for i in range(10):\\n            new_temp = 20.0 + random.uniform(-8.0, 8.0) * (i % 3 + 1) / 3\\n            raw_sensor_reading.set(new_temp)\\n            print(f&amp;quot;Raw sensor: {new_temp:.2f}¬∞C&amp;quot; + \\n                (&amp;quot; (out of range)&amp;quot; if not (15.0 &amp;lt;= new_temp &amp;lt;= 30.0) else &amp;quot;&amp;quot;))\\n            await asyncio.sleep(0.3)  # Sensor sends data every 300ms\\n\\n        print(&amp;quot;...waiting for final intervals...&amp;quot;)\\n        await asyncio.sleep(2.5)\\n        print(&amp;quot;Done.&amp;quot;)\\n\\n    await simulate_sensor()\\n\\nasyncio.run(main())\\n# Sample output (values will vary):\\n# Simulating sensor readings...\\n# Raw sensor: 19.16¬∞C\\n# Raw sensor: 22.45¬∞C\\n# TREND ALERT: 19.16¬∞C ‚Üí 22.45¬∞C (Œî3.29¬∞C)\\n# Raw sensor: 17.90¬∞C\\n# DB WRITE: 22.45¬∞C (debounced)\\n# TREND ALERT: 22.45¬∞C ‚Üí 17.90¬∞C (Œî-4.55¬∞C)\\n# Raw sensor: 24.32¬∞C\\n# DASHBOARD: 24.32¬∞C (throttled)\\n# DB WRITE: 17.90¬∞C (debounced)\\n# TREND ALERT: 17.90¬∞C ‚Üí 24.32¬∞C (Œî6.42¬∞C)\\n# Raw sensor: 12.67¬∞C (out of range)\\n# Raw sensor: 26.84¬∞C\\n# DB WRITE: 24.32¬∞C (debounced)\\n# DB WRITE: 26.84¬∞C (debounced)\\n# TREND ALERT: 24.32¬∞C ‚Üí 26.84¬∞C (Œî2.52¬∞C)\\n# Raw sensor: 16.52¬∞C\\n# DASHBOARD: 26.84¬∞C (throttled)\\n# TREND ALERT: 26.84¬∞C ‚Üí 16.52¬∞C (Œî-10.32¬∞C)\\n# Raw sensor: 31.48¬∞C (out of range)\\n# Raw sensor: 14.23¬∞C (out of range)\\n# Raw sensor: 28.91¬∞C\\n# DB WRITE: 16.52¬∞C (debounced)\\n# DB WRITE: 28.91¬∞C (debounced)\\n# TREND ALERT: 16.52¬∞C ‚Üí 28.91¬∞C (Œî12.39¬∞C)\\n# ...waiting for final intervals...\\n# DASHBOARD: 28.91¬∞C (throttled)\\n# Done.\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;What this helps with on the &lt;strong&gt;backend&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Filtering:&lt;/strong&gt; Ignore noisy sensor readings outside a valid range, skip processing events that don&amp;#39;t meet certain criteria before hitting a database or external API.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Debouncing:&lt;/strong&gt; Consolidate rapid updates before writing to a database (e.g., update user profile only after they&amp;#39;ve stopped changing fields for 500ms), trigger expensive computations only after a burst of related events settles.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Throttling:&lt;/strong&gt; Limit the rate of outgoing notifications (email, Slack) triggered by frequent internal events, control the frequency of logging for high-volume operations, enforce API rate limits for external services called reactively.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Pairwise:&lt;/strong&gt; Track trends by comparing consecutive values (e.g., monitoring temperature changes, detecting price movements, calculating deltas between readings), invaluable for anomaly detection and temporal analysis of data streams.&lt;/li&gt;\\n&lt;li&gt;Keeps the timing logic encapsulated within the operator, not scattered in your application code.&lt;/li&gt;\\n&lt;li&gt;Works naturally with &lt;code&gt;asyncio&lt;/code&gt; for the time-based operators.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;These are implemented using the same underlying &lt;code&gt;Effect&lt;/code&gt; mechanism within &lt;code&gt;reaktiv&lt;/code&gt;, so they integrate seamlessly with &lt;code&gt;Signal&lt;/code&gt; and &lt;code&gt;ComputeSignal&lt;/code&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;Available on PyPI (&lt;code&gt;pip install reaktiv&lt;/code&gt;). The code is in the &lt;code&gt;reaktiv.operators&lt;/code&gt; module.&lt;/p&gt;\\n\\n&lt;p&gt;How do you typically handle these kinds of event stream manipulations (filtering, rate-limiting, debouncing) in your backend Python services? Still curious about robust patterns people use for managing complex, time-sensitive state changes.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?auto=webp&amp;s=56207cde11a0035ec06ef397c5d3b1e64e0bbbc7', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc24c1eea85da9086e3332c25b2caa16dc048408', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=930d78844ce164a0b0d967d9afc0425570220591', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=616805ceef3594a16dc1d510dcfa332aba4b0b49', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=97d6bfaf53ea55f9722583ef52f26d507776ad90', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4a002b51dce3247050b3e0bddf453b0d1f493db3', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/vWMJd_-HZiT1So4n1xpZKCbyXApL9Qev3vPkwQwFM6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=788368b1e6b9775b16530b07cc6a0d6bce98d768', 'width': 1080, 'height': 540}], 'variants': {}, 'id': '0lEBJJFku7UdDc8MJsdnb0yhawXNo5_EZt_RImOh4tQ'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '7987a74c-04d8-11eb-84ca-0e0ac8b5a78f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': '1k6relk', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'loyoan', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6relk/taming_async_events_backend_uses_for_pairwise/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6relk/taming_async_events_backend_uses_for_pairwise/', 'subreddit_subscribers': 1349732, 'created_utc': 1745499049.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '# Introducing Advanced Alchemy\\n\\n**Advanced Alchemy** is an optimized companion library for SQLAlchemy, designed to supercharge your database models with powerful tooling for migrations, asynchronous support, lifecycle hook and more.\\n\\nYou can find the repository and documentation here:\\n\\n- [GitHub Repository](https://github.com/litestar-org/advanced-alchemy)\\n- [Official Documentation](https://docs.advanced-alchemy.litestar.dev/latest/)\\n\\n## What Advanced Alchemy Does\\n\\nAdvanced Alchemy extends SQLAlchemy with productivity-enhancing features, while keeping full compatibility with the ecosystem you already know.\\n\\nAt its core, Advanced Alchemy offers:\\n\\n- Sync and async repositories, featuring common CRUD and highly optimized bulk operations\\n- Integration with major web frameworks including Litestar, Starlette, FastAPI, Flask, and Sanic (additional contributions welcomed)\\n- Custom-built alembic configuration and CLI with optional framework integration\\n- Utility base classes with audit columns, primary keys and utility functions\\n- Built in `File Object` data type for storing objects:\\n    - Unified interface for various storage backends ([`fsspec`](https://filesystem-spec.readthedocs.io/en/latest/) and [`obstore`](https://developmentseed.org/obstore/latest/))\\n    - Optional lifecycle event hooks integrated with SQLAlchemy\\'s event system to automatically save and delete files as records are inserted, updated, or deleted\\n- Optimized JSON types including a custom JSON type for Oracle\\n- Integrated support for UUID6 and UUID7 using [`uuid-utils`](https://github.com/aminalaee/uuid-utils) (install with the `uuid` extra)\\n- Integrated support for Nano ID using [`fastnanoid`](https://github.com/oliverlambson/fastnanoid) (install with the `nanoid` extra)\\n- Pre-configured base classes with audit columns UUID or Big Integer primary keys and\\n  a [sentinel column](https://docs.sqlalchemy.org/en/20/core/connections.html#configuring-sentinel-columns)\\n- Synchronous and asynchronous repositories featuring:\\n    - Common CRUD operations for SQLAlchemy models\\n    - Bulk inserts, updates, upserts, and deletes with dialect-specific enhancements\\n    - Integrated counts, pagination, sorting, filtering with `LIKE`, `IN`, and dates before and/or after\\n- Tested support for multiple database backends including:\\n    - SQLite via [aiosqlite](https://aiosqlite.omnilib.dev/en/stable/) or [sqlite](https://docs.python.org/3/library/sqlite3.html)\\n    - Postgres via [asyncpg](https://magicstack.github.io/asyncpg/current/) or [psycopg3 (async or sync)](https://www.psycopg.org/psycopg3/)\\n    - MySQL via [asyncmy](https://github.com/long2ice/asyncmy)\\n    - Oracle via [oracledb (async or sync)](https://oracle.github.io/python-oracledb/) (tested on 18c and 23c)\\n    - Google Spanner via [spanner-sqlalchemy](https://github.com/googleapis/python-spanner-sqlalchemy/)\\n    - DuckDB via [duckdb_engine](https://github.com/Mause/duckdb_engine)\\n    - Microsoft SQL Server via [pyodbc](https://github.com/mkleehammer/pyodbc) or [aioodbc](https://github.com/aio-libs/aioodbc)\\n    - CockroachDB via [sqlalchemy-cockroachdb (async or sync)](https://github.com/cockroachdb/sqlalchemy-cockroachdb)\\n- ...and much more\\n\\nThe framework is designed to be lightweight yet powerful, with a clean API that makes it easy to integrate into existing projects.\\n\\nHere‚Äôs a quick example of what you can do with Advanced Alchemy in FastAPI. This shows how to implement CRUD routes for your model and create the necessary search parameters and pagination structure for the `list` route.\\n\\n### FastAPI\\n\\n```py\\n    import datetime\\n    from typing import Annotated, Optional\\n    from uuid import UUID\\n\\n    from fastapi import APIRouter, Depends, FastAPI\\n    from pydantic import BaseModel\\n    from sqlalchemy import ForeignKey\\n    from sqlalchemy.orm import Mapped, mapped_column, relationship\\n\\n    from advanced_alchemy.extensions.fastapi import (\\n        AdvancedAlchemy,\\n        AsyncSessionConfig,\\n        SQLAlchemyAsyncConfig,\\n        base,\\n        filters,\\n        repository,\\n        service,\\n    )\\n\\n    sqlalchemy_config = SQLAlchemyAsyncConfig(\\n        connection_string=\"sqlite+aiosqlite:///test.sqlite\",\\n        session_config=AsyncSessionConfig(expire_on_commit=False),\\n        create_all=True,\\n    )\\n    app = FastAPI()\\n    alchemy = AdvancedAlchemy(config=sqlalchemy_config, app=app)\\n    author_router = APIRouter()\\n\\n\\n    class BookModel(base.UUIDAuditBase):\\n        __tablename__ = \"book\"\\n        title: Mapped[str]\\n        author_id: Mapped[UUID] = mapped_column(ForeignKey(\"author.id\"))\\n        author: Mapped[\"AuthorModel\"] = relationship(lazy=\"joined\", innerjoin=True, viewonly=True)\\n\\n\\n    # The SQLAlchemy base includes a declarative model for you to use in your models\\n    # The `Base` class includes a `UUID` based primary key (`id`)\\n    class AuthorModel(base.UUIDBase):\\n        # We can optionally provide the table name instead of auto-generating it\\n        __tablename__ = \"author\"\\n        name: Mapped[str]\\n        dob: Mapped[Optional[datetime.date]]\\n        books: Mapped[list[BookModel]] = relationship(back_populates=\"author\", lazy=\"selectin\")\\n\\n\\n    class AuthorService(service.SQLAlchemyAsyncRepositoryService[AuthorModel]):\\n        \"\"\"Author repository.\"\"\"\\n\\n        class Repo(repository.SQLAlchemyAsyncRepository[AuthorModel]):\\n            \"\"\"Author repository.\"\"\"\\n\\n            model_type = AuthorModel\\n\\n        repository_type = Repo\\n\\n\\n    # Pydantic Models\\n    class Author(BaseModel):\\n        id: Optional[UUID]\\n        name: str\\n        dob: Optional[datetime.date]\\n\\n\\n    class AuthorCreate(BaseModel):\\n        name: str\\n        dob: Optional[datetime.date]\\n\\n\\n    class AuthorUpdate(BaseModel):\\n        name: Optional[str]\\n        dob: Optional[datetime.date]\\n\\n\\n    @author_router.get(path=\"/authors\", response_model=service.OffsetPagination[Author])\\n    async def list_authors(\\n        authors_service: Annotated[\\n            AuthorService, Depends(alchemy.provide_service(AuthorService, load=[AuthorModel.books]))\\n        ],\\n        filters: Annotated[\\n            list[filters.FilterTypes],\\n            Depends(\\n                alchemy.provide_filters(\\n                    {\\n                        \"id_filter\": UUID,\\n                        \"pagination_type\": \"limit_offset\",\\n                        \"search\": \"name\",\\n                        \"search_ignore_case\": True,\\n                    }\\n                )\\n            ),\\n        ],\\n    ) -&gt; service.OffsetPagination[AuthorModel]:\\n        results, total = await authors_service.list_and_count(*filters)\\n        return authors_service.to_schema(results, total, filters=filters)\\n\\n\\n    @author_router.post(path=\"/authors\", response_model=Author)\\n    async def create_author(\\n        authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n        data: AuthorCreate,\\n    ) -&gt; AuthorModel:\\n        obj = await authors_service.create(data)\\n        return authors_service.to_schema(obj)\\n\\n\\n    # We override the authors_repo to use the version that joins the Books in\\n    @author_router.get(path=\"/authors/{author_id}\", response_model=Author)\\n    async def get_author(\\n        authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n        author_id: UUID,\\n    ) -&gt; AuthorModel:\\n        obj = await authors_service.get(author_id)\\n        return authors_service.to_schema(obj)\\n\\n\\n    @author_router.patch(\\n        path=\"/authors/{author_id}\",\\n        response_model=Author,\\n    )\\n    async def update_author(\\n        authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n        data: AuthorUpdate,\\n        author_id: UUID,\\n    ) -&gt; AuthorModel:\\n        obj = await authors_service.update(data, item_id=author_id)\\n        return authors_service.to_schema(obj)\\n\\n\\n    @author_router.delete(path=\"/authors/{author_id}\")\\n    async def delete_author(\\n        authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n        author_id: UUID,\\n    ) -&gt; None:\\n        _ = await authors_service.delete(author_id)\\n\\n\\n    app.include_router(author_router)\\n```\\n\\nFor complete examples, check out the FastAPI implementation [here](https://github.com/litestar-org/advanced-alchemy/blob/main/examples/fastapi/fastapi_service.py) and the Litestar version [here](https://github.com/litestar-org/advanced-alchemy/blob/main/examples/litestar/litestar_service.py). \\n\\nBoth of these examples implement the same configuration, so it\\'s easy to see how portable code becomes between the two frameworks.\\n\\n## Target Audience\\n\\nAdvanced Alchemy is particularly valuable for:\\n\\n1. **Python Backend Developers**: Anyone building fast, modern, API-first applications with sync or async SQLAlchemy and frameworks like Litestar or FastAPI.\\n2. **Teams Scaling Applications**: Teams looking to scale their projects with clean architecture, separation of concerns, and maintainable data layers.\\n3. **Data-Driven Projects**: Projects that require advanced data modeling, migrations, and lifecycle management without the overhead of manually stitching tools together.\\n4. **Large Application**: The patterns available reduce the amount of boilerplate required to manage projects with a large number of models or data interactions.\\n\\nIf you‚Äôve ever wanted to streamline your data layer, use async ORM features painlessly, or avoid the complexity of setting up migrations and repositories from scratch, Advanced Alchemy is exactly what you need.\\n\\n## Getting Started\\n\\nAdvanced Alchemy is available on [PyPI](https://pypi.org/project/advanced-alchemy/):\\n\\n```bash\\n    pip install advanced-alchemy\\n```\\n \\nCheck out our [GitHub repository](https://github.com/litestar-org/advanced-alchemy) for documentation and examples. You can also join our [Discord](https://discord.gg/litestar) and if you find it interesting don\\'t forget to add a \"star\" on GitHub!\\n\\n## License\\n\\nAdvanced Alchemy is released under the MIT License.\\n\\n## TLDR\\n\\nA carefully crafted, thoroughly tested, optimized companion library for SQLAlchemy.\\n\\nThere are custom datatypes, a service and repository (including optimized bulk operations), and native integration with Flask, FastAPI, Starlette, Litestar and Sanic.\\n\\nFeedback and enhancements are always welcomed! We have an active discord community, so if you don\\'t get a response on an issue or would like to chat directly with the dev team, please reach out.\\n\\n\\n', 'author_fullname': 't2_vhuhuhlg', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Advanced Alchemy 1.0 - A framework agnostic library for SQLAlchemy', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5z534', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.95, 'author_flair_background_color': '#202235', 'subreddit_type': 'public', 'ups': 132, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': 'b637fbec-45df-11ee-b3f3-36a8be1bdee8', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 132, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1745427585.0, 'author_flair_css_class': None, 'author_flair_richtext': [{'a': ':litestar-logo:', 'e': 'emoji', 'u': 'https://emoji.redditmedia.com/a0zgnzwzd9kb1_t5_2qh0y/litestar-logo'}, {'e': 'text', 't': ' Litestar Maintainer'}], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745414810.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'richtext', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Introducing Advanced Alchemy&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Advanced Alchemy&lt;/strong&gt; is an optimized companion library for SQLAlchemy, designed to supercharge your database models with powerful tooling for migrations, asynchronous support, lifecycle hook and more.&lt;/p&gt;\\n\\n&lt;p&gt;You can find the repository and documentation here:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;a href=\"https://github.com/litestar-org/advanced-alchemy\"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\"https://docs.advanced-alchemy.litestar.dev/latest/\"&gt;Official Documentation&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h2&gt;What Advanced Alchemy Does&lt;/h2&gt;\\n\\n&lt;p&gt;Advanced Alchemy extends SQLAlchemy with productivity-enhancing features, while keeping full compatibility with the ecosystem you already know.&lt;/p&gt;\\n\\n&lt;p&gt;At its core, Advanced Alchemy offers:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Sync and async repositories, featuring common CRUD and highly optimized bulk operations&lt;/li&gt;\\n&lt;li&gt;Integration with major web frameworks including Litestar, Starlette, FastAPI, Flask, and Sanic (additional contributions welcomed)&lt;/li&gt;\\n&lt;li&gt;Custom-built alembic configuration and CLI with optional framework integration&lt;/li&gt;\\n&lt;li&gt;Utility base classes with audit columns, primary keys and utility functions&lt;/li&gt;\\n&lt;li&gt;Built in &lt;code&gt;File Object&lt;/code&gt; data type for storing objects:\\n\\n&lt;ul&gt;\\n&lt;li&gt;Unified interface for various storage backends (&lt;a href=\"https://filesystem-spec.readthedocs.io/en/latest/\"&gt;&lt;code&gt;fsspec&lt;/code&gt;&lt;/a&gt; and &lt;a href=\"https://developmentseed.org/obstore/latest/\"&gt;&lt;code&gt;obstore&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;\\n&lt;li&gt;Optional lifecycle event hooks integrated with SQLAlchemy&amp;#39;s event system to automatically save and delete files as records are inserted, updated, or deleted&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;Optimized JSON types including a custom JSON type for Oracle&lt;/li&gt;\\n&lt;li&gt;Integrated support for UUID6 and UUID7 using &lt;a href=\"https://github.com/aminalaee/uuid-utils\"&gt;&lt;code&gt;uuid-utils&lt;/code&gt;&lt;/a&gt; (install with the &lt;code&gt;uuid&lt;/code&gt; extra)&lt;/li&gt;\\n&lt;li&gt;Integrated support for Nano ID using &lt;a href=\"https://github.com/oliverlambson/fastnanoid\"&gt;&lt;code&gt;fastnanoid&lt;/code&gt;&lt;/a&gt; (install with the &lt;code&gt;nanoid&lt;/code&gt; extra)&lt;/li&gt;\\n&lt;li&gt;Pre-configured base classes with audit columns UUID or Big Integer primary keys and\\na &lt;a href=\"https://docs.sqlalchemy.org/en/20/core/connections.html#configuring-sentinel-columns\"&gt;sentinel column&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Synchronous and asynchronous repositories featuring:\\n\\n&lt;ul&gt;\\n&lt;li&gt;Common CRUD operations for SQLAlchemy models&lt;/li&gt;\\n&lt;li&gt;Bulk inserts, updates, upserts, and deletes with dialect-specific enhancements&lt;/li&gt;\\n&lt;li&gt;Integrated counts, pagination, sorting, filtering with &lt;code&gt;LIKE&lt;/code&gt;, &lt;code&gt;IN&lt;/code&gt;, and dates before and/or after&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;Tested support for multiple database backends including:\\n\\n&lt;ul&gt;\\n&lt;li&gt;SQLite via &lt;a href=\"https://aiosqlite.omnilib.dev/en/stable/\"&gt;aiosqlite&lt;/a&gt; or &lt;a href=\"https://docs.python.org/3/library/sqlite3.html\"&gt;sqlite&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Postgres via &lt;a href=\"https://magicstack.github.io/asyncpg/current/\"&gt;asyncpg&lt;/a&gt; or &lt;a href=\"https://www.psycopg.org/psycopg3/\"&gt;psycopg3 (async or sync)&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;MySQL via &lt;a href=\"https://github.com/long2ice/asyncmy\"&gt;asyncmy&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Oracle via &lt;a href=\"https://oracle.github.io/python-oracledb/\"&gt;oracledb (async or sync)&lt;/a&gt; (tested on 18c and 23c)&lt;/li&gt;\\n&lt;li&gt;Google Spanner via &lt;a href=\"https://github.com/googleapis/python-spanner-sqlalchemy/\"&gt;spanner-sqlalchemy&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;DuckDB via &lt;a href=\"https://github.com/Mause/duckdb_engine\"&gt;duckdb_engine&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;Microsoft SQL Server via &lt;a href=\"https://github.com/mkleehammer/pyodbc\"&gt;pyodbc&lt;/a&gt; or &lt;a href=\"https://github.com/aio-libs/aioodbc\"&gt;aioodbc&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;CockroachDB via &lt;a href=\"https://github.com/cockroachdb/sqlalchemy-cockroachdb\"&gt;sqlalchemy-cockroachdb (async or sync)&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;...and much more&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The framework is designed to be lightweight yet powerful, with a clean API that makes it easy to integrate into existing projects.&lt;/p&gt;\\n\\n&lt;p&gt;Here‚Äôs a quick example of what you can do with Advanced Alchemy in FastAPI. This shows how to implement CRUD routes for your model and create the necessary search parameters and pagination structure for the &lt;code&gt;list&lt;/code&gt; route.&lt;/p&gt;\\n\\n&lt;h3&gt;FastAPI&lt;/h3&gt;\\n\\n&lt;p&gt;```py\\n    import datetime\\n    from typing import Annotated, Optional\\n    from uuid import UUID&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;from fastapi import APIRouter, Depends, FastAPI\\nfrom pydantic import BaseModel\\nfrom sqlalchemy import ForeignKey\\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\\n\\nfrom advanced_alchemy.extensions.fastapi import (\\n    AdvancedAlchemy,\\n    AsyncSessionConfig,\\n    SQLAlchemyAsyncConfig,\\n    base,\\n    filters,\\n    repository,\\n    service,\\n)\\n\\nsqlalchemy_config = SQLAlchemyAsyncConfig(\\n    connection_string=&amp;quot;sqlite+aiosqlite:///test.sqlite&amp;quot;,\\n    session_config=AsyncSessionConfig(expire_on_commit=False),\\n    create_all=True,\\n)\\napp = FastAPI()\\nalchemy = AdvancedAlchemy(config=sqlalchemy_config, app=app)\\nauthor_router = APIRouter()\\n\\n\\nclass BookModel(base.UUIDAuditBase):\\n    __tablename__ = &amp;quot;book&amp;quot;\\n    title: Mapped[str]\\n    author_id: Mapped[UUID] = mapped_column(ForeignKey(&amp;quot;author.id&amp;quot;))\\n    author: Mapped[&amp;quot;AuthorModel&amp;quot;] = relationship(lazy=&amp;quot;joined&amp;quot;, innerjoin=True, viewonly=True)\\n\\n\\n# The SQLAlchemy base includes a declarative model for you to use in your models\\n# The `Base` class includes a `UUID` based primary key (`id`)\\nclass AuthorModel(base.UUIDBase):\\n    # We can optionally provide the table name instead of auto-generating it\\n    __tablename__ = &amp;quot;author&amp;quot;\\n    name: Mapped[str]\\n    dob: Mapped[Optional[datetime.date]]\\n    books: Mapped[list[BookModel]] = relationship(back_populates=&amp;quot;author&amp;quot;, lazy=&amp;quot;selectin&amp;quot;)\\n\\n\\nclass AuthorService(service.SQLAlchemyAsyncRepositoryService[AuthorModel]):\\n    &amp;quot;&amp;quot;&amp;quot;Author repository.&amp;quot;&amp;quot;&amp;quot;\\n\\n    class Repo(repository.SQLAlchemyAsyncRepository[AuthorModel]):\\n        &amp;quot;&amp;quot;&amp;quot;Author repository.&amp;quot;&amp;quot;&amp;quot;\\n\\n        model_type = AuthorModel\\n\\n    repository_type = Repo\\n\\n\\n# Pydantic Models\\nclass Author(BaseModel):\\n    id: Optional[UUID]\\n    name: str\\n    dob: Optional[datetime.date]\\n\\n\\nclass AuthorCreate(BaseModel):\\n    name: str\\n    dob: Optional[datetime.date]\\n\\n\\nclass AuthorUpdate(BaseModel):\\n    name: Optional[str]\\n    dob: Optional[datetime.date]\\n\\n\\n@author_router.get(path=&amp;quot;/authors&amp;quot;, response_model=service.OffsetPagination[Author])\\nasync def list_authors(\\n    authors_service: Annotated[\\n        AuthorService, Depends(alchemy.provide_service(AuthorService, load=[AuthorModel.books]))\\n    ],\\n    filters: Annotated[\\n        list[filters.FilterTypes],\\n        Depends(\\n            alchemy.provide_filters(\\n                {\\n                    &amp;quot;id_filter&amp;quot;: UUID,\\n                    &amp;quot;pagination_type&amp;quot;: &amp;quot;limit_offset&amp;quot;,\\n                    &amp;quot;search&amp;quot;: &amp;quot;name&amp;quot;,\\n                    &amp;quot;search_ignore_case&amp;quot;: True,\\n                }\\n            )\\n        ),\\n    ],\\n) -&amp;gt; service.OffsetPagination[AuthorModel]:\\n    results, total = await authors_service.list_and_count(*filters)\\n    return authors_service.to_schema(results, total, filters=filters)\\n\\n\\n@author_router.post(path=&amp;quot;/authors&amp;quot;, response_model=Author)\\nasync def create_author(\\n    authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n    data: AuthorCreate,\\n) -&amp;gt; AuthorModel:\\n    obj = await authors_service.create(data)\\n    return authors_service.to_schema(obj)\\n\\n\\n# We override the authors_repo to use the version that joins the Books in\\n@author_router.get(path=&amp;quot;/authors/{author_id}&amp;quot;, response_model=Author)\\nasync def get_author(\\n    authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n    author_id: UUID,\\n) -&amp;gt; AuthorModel:\\n    obj = await authors_service.get(author_id)\\n    return authors_service.to_schema(obj)\\n\\n\\n@author_router.patch(\\n    path=&amp;quot;/authors/{author_id}&amp;quot;,\\n    response_model=Author,\\n)\\nasync def update_author(\\n    authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n    data: AuthorUpdate,\\n    author_id: UUID,\\n) -&amp;gt; AuthorModel:\\n    obj = await authors_service.update(data, item_id=author_id)\\n    return authors_service.to_schema(obj)\\n\\n\\n@author_router.delete(path=&amp;quot;/authors/{author_id}&amp;quot;)\\nasync def delete_author(\\n    authors_service: Annotated[AuthorService, Depends(alchemy.provide_service(AuthorService))],\\n    author_id: UUID,\\n) -&amp;gt; None:\\n    _ = await authors_service.delete(author_id)\\n\\n\\napp.include_router(author_router)\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;```&lt;/p&gt;\\n\\n&lt;p&gt;For complete examples, check out the FastAPI implementation &lt;a href=\"https://github.com/litestar-org/advanced-alchemy/blob/main/examples/fastapi/fastapi_service.py\"&gt;here&lt;/a&gt; and the Litestar version &lt;a href=\"https://github.com/litestar-org/advanced-alchemy/blob/main/examples/litestar/litestar_service.py\"&gt;here&lt;/a&gt;. &lt;/p&gt;\\n\\n&lt;p&gt;Both of these examples implement the same configuration, so it&amp;#39;s easy to see how portable code becomes between the two frameworks.&lt;/p&gt;\\n\\n&lt;h2&gt;Target Audience&lt;/h2&gt;\\n\\n&lt;p&gt;Advanced Alchemy is particularly valuable for:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Python Backend Developers&lt;/strong&gt;: Anyone building fast, modern, API-first applications with sync or async SQLAlchemy and frameworks like Litestar or FastAPI.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Teams Scaling Applications&lt;/strong&gt;: Teams looking to scale their projects with clean architecture, separation of concerns, and maintainable data layers.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Data-Driven Projects&lt;/strong&gt;: Projects that require advanced data modeling, migrations, and lifecycle management without the overhead of manually stitching tools together.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Large Application&lt;/strong&gt;: The patterns available reduce the amount of boilerplate required to manage projects with a large number of models or data interactions.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;If you‚Äôve ever wanted to streamline your data layer, use async ORM features painlessly, or avoid the complexity of setting up migrations and repositories from scratch, Advanced Alchemy is exactly what you need.&lt;/p&gt;\\n\\n&lt;h2&gt;Getting Started&lt;/h2&gt;\\n\\n&lt;p&gt;Advanced Alchemy is available on &lt;a href=\"https://pypi.org/project/advanced-alchemy/\"&gt;PyPI&lt;/a&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;bash\\n    pip install advanced-alchemy\\n&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Check out our &lt;a href=\"https://github.com/litestar-org/advanced-alchemy\"&gt;GitHub repository&lt;/a&gt; for documentation and examples. You can also join our &lt;a href=\"https://discord.gg/litestar\"&gt;Discord&lt;/a&gt; and if you find it interesting don&amp;#39;t forget to add a &amp;quot;star&amp;quot; on GitHub!&lt;/p&gt;\\n\\n&lt;h2&gt;License&lt;/h2&gt;\\n\\n&lt;p&gt;Advanced Alchemy is released under the MIT License.&lt;/p&gt;\\n\\n&lt;h2&gt;TLDR&lt;/h2&gt;\\n\\n&lt;p&gt;A carefully crafted, thoroughly tested, optimized companion library for SQLAlchemy.&lt;/p&gt;\\n\\n&lt;p&gt;There are custom datatypes, a service and repository (including optimized bulk operations), and native integration with Flask, FastAPI, Starlette, Litestar and Sanic.&lt;/p&gt;\\n\\n&lt;p&gt;Feedback and enhancements are always welcomed! We have an active discord community, so if you don&amp;#39;t get a response on an issue or would like to chat directly with the dev team, please reach out.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?auto=webp&amp;s=e3cb77f131af7d6aa954dfb0a6d6b81541ae6ec0', 'width': 4688, 'height': 1563}, 'resolutions': [{'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5b2018b102297b05e951402b817c4d5babbe095c', 'width': 108, 'height': 36}, {'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5919ece428818e933016195642319ac028de746', 'width': 216, 'height': 72}, {'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91ccdfe469597723440a350a74366a3ad9091e9a', 'width': 320, 'height': 106}, {'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b8782ef90b47ce4eacedf289f6dcfc9109c7def4', 'width': 640, 'height': 213}, {'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dec6524fb077e57f16ac895c5ea4ed0e52782f96', 'width': 960, 'height': 320}, {'url': 'https://external-preview.redd.it/ql6F1WSmiIif_PKMChoaqiF3EzR0SiQzuOc7Aqz-KEQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4d4a6dd9549a29eed43ff2298448b6ef797d34c2', 'width': 1080, 'height': 360}], 'variants': {}, 'id': 'IsMJSX4tPW1zjyfzVdQaQCgB3C_zhC3d7w5VlX5TdIs'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': ':litestar-logo: Litestar Maintainer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k5z534', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cofin_', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'light', 'permalink': '/r/Python/comments/1k5z534/advanced_alchemy_10_a_framework_agnostic_library/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5z534/advanced_alchemy_10_a_framework_agnostic_library/', 'subreddit_subscribers': 1349732, 'created_utc': 1745414810.0, 'num_crossposts': 1, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'Hi everyone! A few months ago I shared \\\\*\\\\*iFetch\\\\*\\\\*, my Python utility for bulk iCloud Drive downloads. Since then I‚Äôve fully refactored it and added powerful new features: modular code, parallel ‚Äúdelta-sync‚Äù transfers that only fetch changed chunks, resume-capable downloads with exponential backoff, and structured JSON logging for rock-solid backups and migrations.\\n\\n# What My Project Does\\n\\niFetch v2.0 breaks the logic into clear modules (logger, models, utils, chunker, tracker, downloader, CLI), leverages HTTP Range to patch only changed byte ranges, uses a thread pool for concurrent downloads, and writes detailed JSON logs plus a final summary report.\\n\\n# Target Audience\\n\\nIdeal for power users, sysadmins, and developers who need reliable iCloud data recovery, account migrations, or local backups of large directories‚Äîespecially when Apple‚Äôs native tools fall short.\\n\\n# Comparison\\n\\nUnlike Apple‚Äôs built-in interfaces, iFetch v2.0:\\n\\n\\\\- \\\\*\\\\*Saves bandwidth\\\\*\\\\* by syncing only what‚Äôs changed\\n\\n\\\\- \\\\*\\\\*Survives network hiccups\\\\*\\\\* with retries &amp; checkpointed resumes\\n\\n\\\\- \\\\*\\\\*Scales\\\\*\\\\* across multiple CPU cores for bulk transfers\\n\\n\\\\- \\\\*\\\\*Gives full visibility\\\\*\\\\* via JSON logs and end-of-run reports\\n\\n# Check it out on GitHub\\n\\n[https://github.com/roshanlam/iFetch](https://github.com/roshanlam/iFetch)\\n\\nFeedback is welcome! üòä', 'author_fullname': 't2_1dvoq7fvx3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'iFetch v2.0: A Python Tool for Bulk iCloud Drive Downloads', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6ipim', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745465903.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! A few months ago I shared **iFetch**, my Python utility for bulk iCloud Drive downloads. Since then I‚Äôve fully refactored it and added powerful new features: modular code, parallel ‚Äúdelta-sync‚Äù transfers that only fetch changed chunks, resume-capable downloads with exponential backoff, and structured JSON logging for rock-solid backups and migrations.&lt;/p&gt;\\n\\n&lt;h1&gt;What My Project Does&lt;/h1&gt;\\n\\n&lt;p&gt;iFetch v2.0 breaks the logic into clear modules (logger, models, utils, chunker, tracker, downloader, CLI), leverages HTTP Range to patch only changed byte ranges, uses a thread pool for concurrent downloads, and writes detailed JSON logs plus a final summary report.&lt;/p&gt;\\n\\n&lt;h1&gt;Target Audience&lt;/h1&gt;\\n\\n&lt;p&gt;Ideal for power users, sysadmins, and developers who need reliable iCloud data recovery, account migrations, or local backups of large directories‚Äîespecially when Apple‚Äôs native tools fall short.&lt;/p&gt;\\n\\n&lt;h1&gt;Comparison&lt;/h1&gt;\\n\\n&lt;p&gt;Unlike Apple‚Äôs built-in interfaces, iFetch v2.0:&lt;/p&gt;\\n\\n&lt;p&gt;- **Saves bandwidth** by syncing only what‚Äôs changed&lt;/p&gt;\\n\\n&lt;p&gt;- **Survives network hiccups** with retries &amp;amp; checkpointed resumes&lt;/p&gt;\\n\\n&lt;p&gt;- **Scales** across multiple CPU cores for bulk transfers&lt;/p&gt;\\n\\n&lt;p&gt;- **Gives full visibility** via JSON logs and end-of-run reports&lt;/p&gt;\\n\\n&lt;h1&gt;Check it out on GitHub&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;a href=\"https://github.com/roshanlam/iFetch\"&gt;https://github.com/roshanlam/iFetch&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Feedback is welcome! üòä&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?auto=webp&amp;s=a10209ed1ae4fce32c186125b00680a3ce389c08', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23bca6f57d1289b6f0f1ce2562f502e5cb7e1054', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=56678daa9438540c317d3903711f978ac04791c8', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d9c5bc130e354eac1265300424ed70f67a6c4afe', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=69e61a54937d2e6c55756fcbe383015e09cb7417', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=aa14100b81117d2637b9c45c2ff5f90bed490490', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/0Ntl60PVrO-bg1ckeSBhHrLsfbZ0QrbaimnOdcKSCRc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b0153b10ee8690b63bee66c55573adc22de5dad2', 'width': 1080, 'height': 540}], 'variants': {}, 'id': '5QMqrxYAVyedz06WeS2CDtBonCkBtPR1dmeukdk8hvg'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k6ipim', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'nepalidj', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6ipim/ifetch_v20_a_python_tool_for_bulk_icloud_drive/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6ipim/ifetch_v20_a_python_tool_for_bulk_icloud_drive/', 'subreddit_subscribers': 1349732, 'created_utc': 1745465903.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'Hey everyone,\\n\\nI‚Äôm working on a survey about **energy-conscious software development** and would really value input from the Software Engineering community. As developers, we often focus on performance, scalability, and maintainability‚Äîbut how often do we explicitly think about energy consumption as a goal? More often than not, energy efficiency improvements happen as a byproduct rather than through deliberate planning.\\n\\nI‚Äôm particularly interested in hearing from those who regularly work with Python‚Äîa widely used language nowadays with potential huge impact on global energy consumption. How do you approach energy optimization in your projects? Is it something you actively think about, or does it just happen as part of your performance improvements?\\n\\nThis survey aims to understand how energy consumption is measured in practice, whether companies actively prioritize energy efficiency, and what challenges developers face when trying to integrate it into their workflows. **Your insights would be incredibly valuable**.\\n\\nThe survey is part of a research project conducted by the **Chair of Software Systems at Leipzig University**. Your participation would help us gather practical insights from real-world development experiences. It only takes around **15 minutes**:  \\nüëâ [Take the survey here](https://umfrage.uni-leipzig.de/index.php/762399?lang=en)\\n\\nThanks for sharing your thoughts!', 'author_fullname': 't2_9qlhalmh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Survey: Energy Efficiency in Software Development ‚Äì Just a Side Effect?', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6lc8p', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.63, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745475560.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\\n\\n&lt;p&gt;I‚Äôm working on a survey about &lt;strong&gt;energy-conscious software development&lt;/strong&gt; and would really value input from the Software Engineering community. As developers, we often focus on performance, scalability, and maintainability‚Äîbut how often do we explicitly think about energy consumption as a goal? More often than not, energy efficiency improvements happen as a byproduct rather than through deliberate planning.&lt;/p&gt;\\n\\n&lt;p&gt;I‚Äôm particularly interested in hearing from those who regularly work with Python‚Äîa widely used language nowadays with potential huge impact on global energy consumption. How do you approach energy optimization in your projects? Is it something you actively think about, or does it just happen as part of your performance improvements?&lt;/p&gt;\\n\\n&lt;p&gt;This survey aims to understand how energy consumption is measured in practice, whether companies actively prioritize energy efficiency, and what challenges developers face when trying to integrate it into their workflows. &lt;strong&gt;Your insights would be incredibly valuable&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;The survey is part of a research project conducted by the &lt;strong&gt;Chair of Software Systems at Leipzig University&lt;/strong&gt;. Your participation would help us gather practical insights from real-world development experiences. It only takes around &lt;strong&gt;15 minutes&lt;/strong&gt;:&lt;br/&gt;\\nüëâ &lt;a href=\"https://umfrage.uni-leipzig.de/index.php/762399?lang=en\"&gt;Take the survey here&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Thanks for sharing your thoughts!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k6lc8p', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Embarrassed_Path_264', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6lc8p/survey_energy_efficiency_in_software_development/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6lc8p/survey_energy_efficiency_in_software_development/', 'subreddit_subscribers': 1349732, 'created_utc': 1745475560.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '# Goombay\\n\\nIf you have any questions or ideas, feel free to leave them in this project\\'s [discord server](https://discord.gg/SDUNcjzaEh)! There are also several other bioinformatics-related projects, a website, and a game in the works!\\n\\n# What My Project Does\\n\\n**Goombay** is a Python project which contains several sequence alignment algorithms. This package can calculate distance (and similarity), show alignment, and display the underlying matrices for Needleman-Wunsch, Gotoh, Smith-Waterman, Wagner-Fischer, Waterman-Smith-Beyer, Lowrance-Wagner, Longest Common Subsequence, and Shortest Common Supersequence algorithms! With more alignment algorithms to come!\\n\\n**Main Features**\\n\\n* Global and Local sequence alignment\\n* Common method interface between classes for ease of use\\n* Class-based and instance-based use (customizable parameters)\\n* Scoring, matrix visualization, and formatted sequence alignment\\n* Thorough testing\\n\\nFor all features check out the full readme at\\xa0[GitHub](https://github.com/lignum-vitae/goombay)\\xa0or\\xa0[PyPI](https://pypi.org/project/goombay/).\\n\\n# Target Audience\\n\\nThis API is designed for researchers or any programmer looking to use sequence alignment in their workflow.\\n\\n# Comparison\\n\\nThere are many other examples of sequence alignment PyPI packages but my specific project was meant to expand on the functionality of [textdistance](https://github.com/life4/textdistance)! In addition to adding more choices, this project also adds a few algorithms not present in textdistance!\\n\\n# Basic Example\\n\\n    from goombay import needleman_wunsch\\n    \\n    print(needleman_wunsch.distance(\"ACTG\",\"FHYU\"))\\n    # 4\\n    print(needleman_wunsch.distance(\"ACTG\",\"ACTG\"))\\n    # 0\\n    print(needleman_wunsch.similarity(\"ACTG\",\"FHYU\"))\\n    # 0\\n    print(needleman_wunsch.similarity(\"ACTG\",\"ACTG\"))\\n    # 4\\n    print(needleman_wunsch.normalized_distance(\"ACTG\",\"AATG\"))\\n    #0.25\\n    print(needleman_wunsch.normalized_similarity(\"ACTG\",\"AATG\"))\\n    #0.75\\n    print(needleman_wunsch.align(\"BA\",\"ABA\"))\\n    #-BA\\n    #ABA\\n    print(needleman_wunsch.matrix(\"AFTG\",\"ACTG\"))\\n    [[0. 2. 4. 6. 8.]\\n     [2. 0. 2. 4. 6.]\\n     [4. 2. 1. 3. 5.]\\n     [6. 4. 3. 1. 3.]\\n     [8. 6. 5. 3. 1.]]', 'author_fullname': 't2_omjtu643v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Goombay: For all your sequence alignment needs', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6259g', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 13, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 13, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745422400.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Goombay&lt;/h1&gt;\\n\\n&lt;p&gt;If you have any questions or ideas, feel free to leave them in this project&amp;#39;s &lt;a href=\"https://discord.gg/SDUNcjzaEh\"&gt;discord server&lt;/a&gt;! There are also several other bioinformatics-related projects, a website, and a game in the works!&lt;/p&gt;\\n\\n&lt;h1&gt;What My Project Does&lt;/h1&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Goombay&lt;/strong&gt; is a Python project which contains several sequence alignment algorithms. This package can calculate distance (and similarity), show alignment, and display the underlying matrices for Needleman-Wunsch, Gotoh, Smith-Waterman, Wagner-Fischer, Waterman-Smith-Beyer, Lowrance-Wagner, Longest Common Subsequence, and Shortest Common Supersequence algorithms! With more alignment algorithms to come!&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Main Features&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Global and Local sequence alignment&lt;/li&gt;\\n&lt;li&gt;Common method interface between classes for ease of use&lt;/li&gt;\\n&lt;li&gt;Class-based and instance-based use (customizable parameters)&lt;/li&gt;\\n&lt;li&gt;Scoring, matrix visualization, and formatted sequence alignment&lt;/li&gt;\\n&lt;li&gt;Thorough testing&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;For all features check out the full readme at\\xa0&lt;a href=\"https://github.com/lignum-vitae/goombay\"&gt;GitHub&lt;/a&gt;\\xa0or\\xa0&lt;a href=\"https://pypi.org/project/goombay/\"&gt;PyPI&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;h1&gt;Target Audience&lt;/h1&gt;\\n\\n&lt;p&gt;This API is designed for researchers or any programmer looking to use sequence alignment in their workflow.&lt;/p&gt;\\n\\n&lt;h1&gt;Comparison&lt;/h1&gt;\\n\\n&lt;p&gt;There are many other examples of sequence alignment PyPI packages but my specific project was meant to expand on the functionality of &lt;a href=\"https://github.com/life4/textdistance\"&gt;textdistance&lt;/a&gt;! In addition to adding more choices, this project also adds a few algorithms not present in textdistance!&lt;/p&gt;\\n\\n&lt;h1&gt;Basic Example&lt;/h1&gt;\\n\\n&lt;pre&gt;&lt;code&gt;from goombay import needleman_wunsch\\n\\nprint(needleman_wunsch.distance(&amp;quot;ACTG&amp;quot;,&amp;quot;FHYU&amp;quot;))\\n# 4\\nprint(needleman_wunsch.distance(&amp;quot;ACTG&amp;quot;,&amp;quot;ACTG&amp;quot;))\\n# 0\\nprint(needleman_wunsch.similarity(&amp;quot;ACTG&amp;quot;,&amp;quot;FHYU&amp;quot;))\\n# 0\\nprint(needleman_wunsch.similarity(&amp;quot;ACTG&amp;quot;,&amp;quot;ACTG&amp;quot;))\\n# 4\\nprint(needleman_wunsch.normalized_distance(&amp;quot;ACTG&amp;quot;,&amp;quot;AATG&amp;quot;))\\n#0.25\\nprint(needleman_wunsch.normalized_similarity(&amp;quot;ACTG&amp;quot;,&amp;quot;AATG&amp;quot;))\\n#0.75\\nprint(needleman_wunsch.align(&amp;quot;BA&amp;quot;,&amp;quot;ABA&amp;quot;))\\n#-BA\\n#ABA\\nprint(needleman_wunsch.matrix(&amp;quot;AFTG&amp;quot;,&amp;quot;ACTG&amp;quot;))\\n[[0. 2. 4. 6. 8.]\\n [2. 0. 2. 4. 6.]\\n [4. 2. 1. 3. 5.]\\n [6. 4. 3. 1. 3.]\\n [8. 6. 5. 3. 1.]]\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k6259g', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Kind-Kure', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6259g/goombay_for_all_your_sequence_alignment_needs/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6259g/goombay_for_all_your_sequence_alignment_needs/', 'subreddit_subscribers': 1349732, 'created_utc': 1745422400.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"We're delighted to release Slint 1.11 with two exciting updates:\\n\\n‚úÖ Live-Preview features Color &amp; Gradient pickers,  \\n‚úÖ Python Bindings upgraded to Beta.\\n\\nSpeed up your UI development with visual color selection and more robust Python support. Check it out - [https://slint.dev/blog/slint-1.11-released](https://slint.dev/blog/slint-1.11-released)\", 'author_fullname': 't2_1495qjd741', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Declarative GUI toolkit - Slint 1.11 upgrades Python Bindings to Beta üöÄ', 'link_flair_richtext': [{'e': 'text', 't': 'News'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'news', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5wqpr', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 22, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'News', 'can_mod_post': False, 'score': 22, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745407582.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re delighted to release Slint 1.11 with two exciting updates:&lt;/p&gt;\\n\\n&lt;p&gt;‚úÖ Live-Preview features Color &amp;amp; Gradient pickers,&lt;br/&gt;\\n‚úÖ Python Bindings upgraded to Beta.&lt;/p&gt;\\n\\n&lt;p&gt;Speed up your UI development with visual color selection and more robust Python support. Check it out - &lt;a href=\"https://slint.dev/blog/slint-1.11-released\"&gt;https://slint.dev/blog/slint-1.11-released&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?auto=webp&amp;s=6b29e96b7ae29e9792a75250a539730265052250', 'width': 1200, 'height': 627}, 'resolutions': [{'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa9e9786c8a4a0c41f6af8d210b6ea43c2c9f8a9', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=714b7eb00c64e2db5b40fd6b873026cb6377d852', 'width': 216, 'height': 112}, {'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=08f9a8a6b817201a10f071516fee78af757be5ec', 'width': 320, 'height': 167}, {'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4f493bc0e11b20fcd7412621e7885b9a666fbcd', 'width': 640, 'height': 334}, {'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=58072aed25b39721f57e024feabe412dababd0fd', 'width': 960, 'height': 501}, {'url': 'https://external-preview.redd.it/WejRA1TT6KIPJJgMjTfckSVKS2__j8XNEzP-BHK7sRM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=063dad563e5e6513b1726b52cac840f08b5dd4d2', 'width': 1080, 'height': 564}], 'variants': {}, 'id': 'wimxYuLj383H8pk0gEuGNf3t2bCzd8XGeQrMci7m8_I'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0ad780a0-1c5e-11ea-978c-0ee7bacb2bff', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#7193ff', 'id': '1k5wqpr', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'slint-ui', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5wqpr/declarative_gui_toolkit_slint_111_upgrades_python/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5wqpr/declarative_gui_toolkit_slint_111_upgrades_python/', 'subreddit_subscribers': 1349732, 'created_utc': 1745407582.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '**What My Project Does**\\n\\nHi everyone,\\n\\nI made an open-source library for fast vector distance and similarity calculations.\\n\\nAt the moment, it supports:\\n\\n- Euclidean, Manhattan, and Hamming distances\\n- Dot product, cosine, and Jaccard similarities\\n\\nThe library uses SIMD acceleration (AVX, AVX2, AVX512, NEON, and SVE instructions) to speed things up.\\n\\nThe library itself is in C, but it comes with a Python wrapper library (named `HsdPy`), so it can be used directly with NumPy arrays and other Python code.\\n\\nHere‚Äôs the GitHub link if you want to check it out: [https://github.com/habedi/hsdlib/tree/main/bindings/python](https://github.com/habedi/hsdlib/tree/main/bindings/python)', 'author_fullname': 't2_138f5rku2o', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'HsdPy: A Python Library for Vector Similarity with SIMD Acceleration', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k60ci8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 14, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 14, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745417966.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;What My Project Does&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Hi everyone,&lt;/p&gt;\\n\\n&lt;p&gt;I made an open-source library for fast vector distance and similarity calculations.&lt;/p&gt;\\n\\n&lt;p&gt;At the moment, it supports:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Euclidean, Manhattan, and Hamming distances&lt;/li&gt;\\n&lt;li&gt;Dot product, cosine, and Jaccard similarities&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;The library uses SIMD acceleration (AVX, AVX2, AVX512, NEON, and SVE instructions) to speed things up.&lt;/p&gt;\\n\\n&lt;p&gt;The library itself is in C, but it comes with a Python wrapper library (named &lt;code&gt;HsdPy&lt;/code&gt;), so it can be used directly with NumPy arrays and other Python code.&lt;/p&gt;\\n\\n&lt;p&gt;Here‚Äôs the GitHub link if you want to check it out: &lt;a href=\"https://github.com/habedi/hsdlib/tree/main/bindings/python\"&gt;https://github.com/habedi/hsdlib/tree/main/bindings/python&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?auto=webp&amp;s=ae3fc50c3e5ded8305986b1913dc72abd2945854', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1a13f9fac0197f9571e34b4e3937d0b98a8c3c61', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a1bd61a0de0eb3a7ed8b32e6a71c0b11db6fbb2', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31738afdd8fa21f4d3c61ad5dc34c0d5eeb68faf', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cf957066c53d2b217784ef0b5fc3df2f8c253eb0', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6e708cd8357d707474fa767b7b9d10111cc041a', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/-x7qsQY4z77CxPHtxsobgBtz6tuv-xKDVbjsbdw83W4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fb524468f74e995f21b54c8e9f56dc8bbb7d773b', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'ji9xeIN3ypg629degUbAr3Q5oM4qFwqD6G2Ez2K_BKQ'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k60ci8', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'No_Pomegranate7508', 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k60ci8/hsdpy_a_python_library_for_vector_similarity_with/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k60ci8/hsdpy_a_python_library_for_vector_similarity_with/', 'subreddit_subscribers': 1349732, 'created_utc': 1745417966.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"I was reading through CPython's implementation for `deque` and noticed a simple but generally useful optimization to amortize memory overhead of node pointers and increase cache locality of elements by using fixed length blocks of elements per node, so sharing here.\\n\\nI'll apply this next when I have the pleasure of writing a doubly linked list.\\n\\nFrom: [Modules/\\\\_collectionsmodule.c#L88-L94](https://github.com/python/cpython/blob/b5bf8c80a921679b23548453565f6fd1f79901f2/Modules/_collectionsmodule.c#L88-L94)\\n\\n     * Textbook implementations of doubly-linked lists store one datum\\n     * per link, but that gives them a 200% memory overhead (a prev and\\n     * next link for each datum) and it costs one malloc() call per data\\n     * element.  By using fixed-length blocks, the link to data ratio is\\n     * significantly improved and there are proportionally fewer calls\\n     * to malloc() and free().  The data blocks of consecutive pointers\\n     * also improve cache locality.\", 'author_fullname': 't2_e66x4vsy9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"CPython's optimization for doubly linked lists in deque (amortizes 200% link memory overhead)\", 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5nxvt', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.96, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 121, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 121, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745373878.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading through CPython&amp;#39;s implementation for &lt;code&gt;deque&lt;/code&gt; and noticed a simple but generally useful optimization to amortize memory overhead of node pointers and increase cache locality of elements by using fixed length blocks of elements per node, so sharing here.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ll apply this next when I have the pleasure of writing a doubly linked list.&lt;/p&gt;\\n\\n&lt;p&gt;From: &lt;a href=\"https://github.com/python/cpython/blob/b5bf8c80a921679b23548453565f6fd1f79901f2/Modules/_collectionsmodule.c#L88-L94\"&gt;Modules/_collectionsmodule.c#L88-L94&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt; * Textbook implementations of doubly-linked lists store one datum\\n * per link, but that gives them a 200% memory overhead (a prev and\\n * next link for each datum) and it costs one malloc() call per data\\n * element.  By using fixed-length blocks, the link to data ratio is\\n * significantly improved and there are proportionally fewer calls\\n * to malloc() and free().  The data blocks of consecutive pointers\\n * also improve cache locality.\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?auto=webp&amp;s=3a653551f722ccdba3c6cd5d480b017232b5287a', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=faaafffe6bd3b308d5818fd3c5e343184f827366', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d801eed8716f5a68f133b9b041778c1b58125e0', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8030bcfaf04460c94ebfb4947f29c4e3a00b030', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=acb9633988eac3c442e4b58727914338a3de04ea', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f5e59c9902e7c6fe61691294a7eb25bf2f1910de', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/YGEGIta_tusSwy0BzyMw37Oi7OwujmqUyKDDd711dSk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19f7839afd57572c2caafb0bcf1c5c726a73e3f9', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'etC3dY359iTORvnOv12rnKYnTHkFx9ZPhN6jZCEeNXw'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k5nxvt', 'is_robot_indexable': True, 'report_reasons': None, 'author': '_byl', 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5nxvt/cpythons_optimization_for_doubly_linked_lists_in/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5nxvt/cpythons_optimization_for_doubly_linked_lists_in/', 'subreddit_subscribers': 1349732, 'created_utc': 1745373878.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"source code link : [https://github.com/manvith12/quantum-workflow](https://github.com/manvith12/quantum-workflow)\\n\\n(images are uploaded on github readme)\\n\\n# What My Project Does\\n\\nThis project implements a quantum-enhanced scheduler for scientific workflows where tasks have dependency constraints‚Äîmodeled as Directed Acyclic Graphs (DAGs). It uses a Variational Quantum Algorithm (VQA) to assign dependent tasks to compute resources efficiently, minimizing execution time and respecting dependencies. The algorithm is inspired by QAOA-like approaches and runs on both simulated and real quantum backends via Qiskit. The optimization leverages classical-quantum hybrid techniques where a classical optimizer tunes quantum circuit parameters to improve schedule cost iteratively.\\n\\n# Target Audience\\n\\nThis is a research-grade prototype aimed at students, researchers, and enthusiasts exploring practical quantum computing applications in workflow scheduling. It's not ready for production, but serves as an educational tool or a baseline for further development in quantum-assisted scientific scheduling.\\n\\n# Comparison to Existing Alternatives\\n\\nUnlike classical schedulers (like HEFT or greedy DAG mappers), this project explores quantum variational techniques to approach the NP-hard scheduling problem. Unlike brute-force or heuristic methods, it uses parameterized quantum circuits to explore a superposition of task assignments and employs quantum interference to converge toward optimal schedules. While it doesn‚Äôt yet outperform classical methods on large-scale problems, it introduces quantum-native strategies for parallelism, particularly valuable for early experimentation on near-term quantum hardware.\", 'author_fullname': 't2_baa4pxi1', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '(Qiskit) - Quantum Scheduler: Optimize Dependent Workflows Using Variational Quantum Algorithms', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6788l', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.8, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': 'fa1eebc8-537b-11ee-bc7a-e60c595033c2', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [{'e': 'text', 't': 'It works on my machine'}], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745434588.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'richtext', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;source code link : &lt;a href=\"https://github.com/manvith12/quantum-workflow\"&gt;https://github.com/manvith12/quantum-workflow&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;(images are uploaded on github readme)&lt;/p&gt;\\n\\n&lt;h1&gt;What My Project Does&lt;/h1&gt;\\n\\n&lt;p&gt;This project implements a quantum-enhanced scheduler for scientific workflows where tasks have dependency constraints‚Äîmodeled as Directed Acyclic Graphs (DAGs). It uses a Variational Quantum Algorithm (VQA) to assign dependent tasks to compute resources efficiently, minimizing execution time and respecting dependencies. The algorithm is inspired by QAOA-like approaches and runs on both simulated and real quantum backends via Qiskit. The optimization leverages classical-quantum hybrid techniques where a classical optimizer tunes quantum circuit parameters to improve schedule cost iteratively.&lt;/p&gt;\\n\\n&lt;h1&gt;Target Audience&lt;/h1&gt;\\n\\n&lt;p&gt;This is a research-grade prototype aimed at students, researchers, and enthusiasts exploring practical quantum computing applications in workflow scheduling. It&amp;#39;s not ready for production, but serves as an educational tool or a baseline for further development in quantum-assisted scientific scheduling.&lt;/p&gt;\\n\\n&lt;h1&gt;Comparison to Existing Alternatives&lt;/h1&gt;\\n\\n&lt;p&gt;Unlike classical schedulers (like HEFT or greedy DAG mappers), this project explores quantum variational techniques to approach the NP-hard scheduling problem. Unlike brute-force or heuristic methods, it uses parameterized quantum circuits to explore a superposition of task assignments and employs quantum interference to converge toward optimal schedules. While it doesn‚Äôt yet outperform classical methods on large-scale problems, it introduces quantum-native strategies for parallelism, particularly valuable for early experimentation on near-term quantum hardware.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?auto=webp&amp;s=886f9f0ed5bf18763d44c340928baa6ab9f47582', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef34dbfa63e1cdcf417c31eff0d6a6524f492d67', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04d88991361e6aee2d5dbf0ab8cfd5342ea84f3e', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=98cee447ac96cb297570904503e95359217018e6', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab02221b959bbcfa42ec7ca98b1a6a65cedb8ab8', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=12e1dc84fcdffd836086976998dfda05efc01c73', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/9VHQlwis8qaqP5L5K1IoclERFMELukuKz0UYkVCLuEA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=840de0ce3de2a68dc5f397e78f90c277bfd79bdb', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'ug0lWrhbdTS3qCmDIia8Bq5r48nmaEw6jgznANPK4pE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'It works on my machine', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k6788l', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Man-vith', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/Python/comments/1k6788l/qiskit_quantum_scheduler_optimize_dependent/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6788l/qiskit_quantum_scheduler_optimize_dependent/', 'subreddit_subscribers': 1349732, 'created_utc': 1745434588.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"Hi!\\n\\nI'd like to share the first release of [NeXosim-py](https://github.com/asynchronics/nexosim-py), a Python client for our open-source Rust discrete-event simulation framework, [NeXosim](https://github.com/asynchronics/nexosim).\\n\\n**What My Project Does**\\n\\n* **NeXosim** is a general-purpose discrete-event simulation framework (similar in concept to [SimPy](https://simpy.readthedocs.io/en/latest/)) written in Rust, with a strong focus on performance, low latency, and developer-friendliness. Its development is driven by demanding applications like hardware-in-the-loop testing and digital twinning for spacecraft, but it's designed to be adaptable for various simulation needs.\\n* **NeXosim-py** acts as a Python front-end to this Rust core. It uses gRPC to allow you to:\\n   * Control the lifecycle of a NeXosim simulation (init, step, halt).\\n   * Monitor the simulation state and retrieve data.\\n   * Inject and schedule events into the simulation.\\n   * Write test scripts, automation, and data processing pipelines in Python that interact with the high-performance Rust simulation engine.\\n   * Integrate simulation control into larger Python applications, potentially using `asyncio` for concurrent operations.\\n* **Important Note:** While you control and interact with the simulation using Python via `nexosim-py`, the core simulation *models* (the components and logic being simulated) still need to be implemented in Rust using the main NeXosim framework.\\n\\n**Target Audience**\\n\\nThis project is aimed at:\\n\\n* **Python developers/System Engineers/Testers** who need to script, automate, or interact with complex, performance-sensitive discrete-event simulations, especially if the core simulation logic already exists or benefits significantly from Rust's performance characteristics.\\n* **Teams** using NeXosim for simulation model development (in Rust) who want a convenient Python interface for higher-level control, test automation, or integration.\\n* **Researchers or engineers** in fields like aerospace, robotics, or complex systems modeling who require high-fidelity, fast simulations and want to leverage Python for experiment orchestration and analysis.\\n* It is intended for **practical/production use cases** where simulation performance or integration with hardware-in-the-loop systems is important, rather than being just a toy project.\\n\\n**Comparison with Alternatives (e.g., SimPy)**\\n\\n* **vs. Pure Python Simulators (like SimPy):**\\n   * **Performance:** NeXosim's core is Rust-based and highly optimized, potentially offering significantly higher performance and lower latency than pure Python simulators, which can be crucial for complex models or real-time interaction.\\n   * **Language:** SimPy allows you to write the entire simulation (models and control logic) in Python, which can be simpler if you don't need Rust's performance or specific features. NeXosim requires simulation models in Rust, with `nexosim-py` providing the Python control layer.\\n   * **Ecosystem:** SimPy is more mature and has a large ecosystem.\\n* **Key Differentiator:** `nexosim-py` specifically bridges the gap between Python scripting/control and a separate, high-performance Rust simulation engine via gRPC. It's less about building the simulation *in* Python and more about *controlling* a powerful external simulation *from* Python.\\n\\n**Useful Links:**\\n\\n* **NeXosim-py User Guide and API:** [https://nexosim-py.readthedocs.io/](https://nexosim-py.readthedocs.io/)\\n* **NeXosim-py GH Repo:** [https://github.com/asynchronics/nexosim-py](https://github.com/asynchronics/nexosim-py)\\n* **NeXosim (Core Rust Framework) GH repo:** [https://github.com/asynchronics/nexosim](https://github.com/asynchronics/nexosim)\\n\\nHappy to answer any questions!\", 'author_fullname': 't2_o90dkdss', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'First release of NeXosim-py front-end for discrete-event simulation and spacecraft digital-twinning', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k603oy', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745417326.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;d like to share the first release of &lt;a href=\"https://github.com/asynchronics/nexosim-py\"&gt;NeXosim-py&lt;/a&gt;, a Python client for our open-source Rust discrete-event simulation framework, &lt;a href=\"https://github.com/asynchronics/nexosim\"&gt;NeXosim&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;What My Project Does&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;NeXosim&lt;/strong&gt; is a general-purpose discrete-event simulation framework (similar in concept to &lt;a href=\"https://simpy.readthedocs.io/en/latest/\"&gt;SimPy&lt;/a&gt;) written in Rust, with a strong focus on performance, low latency, and developer-friendliness. Its development is driven by demanding applications like hardware-in-the-loop testing and digital twinning for spacecraft, but it&amp;#39;s designed to be adaptable for various simulation needs.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;NeXosim-py&lt;/strong&gt; acts as a Python front-end to this Rust core. It uses gRPC to allow you to:\\n\\n&lt;ul&gt;\\n&lt;li&gt;Control the lifecycle of a NeXosim simulation (init, step, halt).&lt;/li&gt;\\n&lt;li&gt;Monitor the simulation state and retrieve data.&lt;/li&gt;\\n&lt;li&gt;Inject and schedule events into the simulation.&lt;/li&gt;\\n&lt;li&gt;Write test scripts, automation, and data processing pipelines in Python that interact with the high-performance Rust simulation engine.&lt;/li&gt;\\n&lt;li&gt;Integrate simulation control into larger Python applications, potentially using &lt;code&gt;asyncio&lt;/code&gt; for concurrent operations.&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; While you control and interact with the simulation using Python via &lt;code&gt;nexosim-py&lt;/code&gt;, the core simulation &lt;em&gt;models&lt;/em&gt; (the components and logic being simulated) still need to be implemented in Rust using the main NeXosim framework.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Target Audience&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This project is aimed at:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Python developers/System Engineers/Testers&lt;/strong&gt; who need to script, automate, or interact with complex, performance-sensitive discrete-event simulations, especially if the core simulation logic already exists or benefits significantly from Rust&amp;#39;s performance characteristics.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Teams&lt;/strong&gt; using NeXosim for simulation model development (in Rust) who want a convenient Python interface for higher-level control, test automation, or integration.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Researchers or engineers&lt;/strong&gt; in fields like aerospace, robotics, or complex systems modeling who require high-fidelity, fast simulations and want to leverage Python for experiment orchestration and analysis.&lt;/li&gt;\\n&lt;li&gt;It is intended for &lt;strong&gt;practical/production use cases&lt;/strong&gt; where simulation performance or integration with hardware-in-the-loop systems is important, rather than being just a toy project.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Comparison with Alternatives (e.g., SimPy)&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;vs. Pure Python Simulators (like SimPy):&lt;/strong&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Performance:&lt;/strong&gt; NeXosim&amp;#39;s core is Rust-based and highly optimized, potentially offering significantly higher performance and lower latency than pure Python simulators, which can be crucial for complex models or real-time interaction.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Language:&lt;/strong&gt; SimPy allows you to write the entire simulation (models and control logic) in Python, which can be simpler if you don&amp;#39;t need Rust&amp;#39;s performance or specific features. NeXosim requires simulation models in Rust, with &lt;code&gt;nexosim-py&lt;/code&gt; providing the Python control layer.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Ecosystem:&lt;/strong&gt; SimPy is more mature and has a large ecosystem.&lt;/li&gt;\\n&lt;/ul&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Key Differentiator:&lt;/strong&gt; &lt;code&gt;nexosim-py&lt;/code&gt; specifically bridges the gap between Python scripting/control and a separate, high-performance Rust simulation engine via gRPC. It&amp;#39;s less about building the simulation &lt;em&gt;in&lt;/em&gt; Python and more about &lt;em&gt;controlling&lt;/em&gt; a powerful external simulation &lt;em&gt;from&lt;/em&gt; Python.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Useful Links:&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;NeXosim-py User Guide and API:&lt;/strong&gt; &lt;a href=\"https://nexosim-py.readthedocs.io/\"&gt;https://nexosim-py.readthedocs.io/&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;NeXosim-py GH Repo:&lt;/strong&gt; &lt;a href=\"https://github.com/asynchronics/nexosim-py\"&gt;https://github.com/asynchronics/nexosim-py&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;NeXosim (Core Rust Framework) GH repo:&lt;/strong&gt; &lt;a href=\"https://github.com/asynchronics/nexosim\"&gt;https://github.com/asynchronics/nexosim&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Happy to answer any questions!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?auto=webp&amp;s=539fa97c7e86b28e569ffc3a3c1d82f29be8172e', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c3d483042575d061af41e06b612d7b3da1254d5', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=324cc5b604e7b5ba55cdce807c5bbab400d08c51', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=902376e2e76bfb9aaf62b0bdc112c4d1a1eaf709', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6568390c076f1968238cd6b1295050e4ed921cbb', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b897b4c8f0ce563cb0e85644d27ead86ea573794', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/tY-cqq20f2AjTBxFk8gidGgecwVTq3Gg24ea8Yz0Vzc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e03bf0e762fdad87a2d8767736e624099757d30', 'width': 1080, 'height': 540}], 'variants': {}, 'id': '0f2OXy-zS9YQ1xW-FA5Dbbs6GIHp5JTn9UpMUjmht8Q'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k603oy', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'sbarral', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k603oy/first_release_of_nexosimpy_frontend_for/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k603oy/first_release_of_nexosimpy_frontend_for/', 'subreddit_subscribers': 1349732, 'created_utc': 1745417326.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '\\nI am currently pursuing my final semester in Computer Science Engineering, and I am looking for major project ideas based on Python full stack development. I would appreciate it if anyone could suggest some innovative and impactful project topics that align with current industry trends and can help enhance my skills in both frontend and backend development. The project should ideally involve real-world applications and give me an opportunity to explore modern tools and frameworks used in full stack development. Any suggestions or guidance would be greatly appreciated!\\n', 'author_fullname': 't2_tfr0ddgzx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Can any one suggest me major projects idea for end semester in python full stack?', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6irr4', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.37, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745466115.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently pursuing my final semester in Computer Science Engineering, and I am looking for major project ideas based on Python full stack development. I would appreciate it if anyone could suggest some innovative and impactful project topics that align with current industry trends and can help enhance my skills in both frontend and backend development. The project should ideally involve real-world applications and give me an opportunity to explore modern tools and frameworks used in full stack development. Any suggestions or guidance would be greatly appreciated!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k6irr4', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'eric-4u', 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6irr4/can_any_one_suggest_me_major_projects_idea_for/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6irr4/can_any_one_suggest_me_major_projects_idea_for/', 'subreddit_subscribers': 1349732, 'created_utc': 1745466115.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"Hi\\xa0[r/Python](https://www.reddit.com/r/Python/)!\\n\\nI recently compiled 1,000 Python exercises to practice everything from the basics to OOP in a level-based format so you can practice with hundreds of levels and review key programming concepts.\\n\\nA few months ago, I was looking for an app that would allow you to do this, and since I couldn't find anything that was free and/or ad-free in this format, I decided to create it for Android users.\\n\\nI thought it might be handy to have it in an android app so I could practice anywhere, like on the bus on the way to university or during short breaks throughout the day.\\n\\nI'm leaving the app link here in case you find it useful as a resource:  \\n[https://play.google.com/store/apps/details?id=com.initzer\\\\_dev.Koder\\\\_Python\\\\_Exercises](https://play.google.com/store/apps/details?id=com.initzer_dev.Koder_Python_Exercises)\", 'author_fullname': 't2_176o89q0y4', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '1,000 Python exercises', 'link_flair_richtext': [{'e': 'text', 't': 'Resource'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'resource', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k56mio', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 118, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Resource', 'can_mod_post': False, 'score': 118, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745329364.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi\\xa0&lt;a href=\"https://www.reddit.com/r/Python/\"&gt;r/Python&lt;/a&gt;!&lt;/p&gt;\\n\\n&lt;p&gt;I recently compiled 1,000 Python exercises to practice everything from the basics to OOP in a level-based format so you can practice with hundreds of levels and review key programming concepts.&lt;/p&gt;\\n\\n&lt;p&gt;A few months ago, I was looking for an app that would allow you to do this, and since I couldn&amp;#39;t find anything that was free and/or ad-free in this format, I decided to create it for Android users.&lt;/p&gt;\\n\\n&lt;p&gt;I thought it might be handy to have it in an android app so I could practice anywhere, like on the bus on the way to university or during short breaks throughout the day.&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;m leaving the app link here in case you find it useful as a resource:&lt;br/&gt;\\n&lt;a href=\"https://play.google.com/store/apps/details?id=com.initzer_dev.Koder_Python_Exercises\"&gt;https://play.google.com/store/apps/details?id=com.initzer_dev.Koder_Python_Exercises&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/PvjkROA_J8CJIxsOHnb_5cEdrNIdx1RzcW6ZvpdAUbk.jpg?auto=webp&amp;s=3527b6bb39a985c5fc0f8dd7d591f8e72e057183', 'width': 512, 'height': 512}, 'resolutions': [{'url': 'https://external-preview.redd.it/PvjkROA_J8CJIxsOHnb_5cEdrNIdx1RzcW6ZvpdAUbk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b98b91261c3fa8fa9d387f5b7974fa2fbdcd255a', 'width': 108, 'height': 108}, {'url': 'https://external-preview.redd.it/PvjkROA_J8CJIxsOHnb_5cEdrNIdx1RzcW6ZvpdAUbk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d71a9e1af35fbe5e9f3524d2251bf5c62d8218e7', 'width': 216, 'height': 216}, {'url': 'https://external-preview.redd.it/PvjkROA_J8CJIxsOHnb_5cEdrNIdx1RzcW6ZvpdAUbk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c5235061e00dd8334f85a56c66fbf3339ceb021', 'width': 320, 'height': 320}], 'variants': {}, 'id': 'f2UwWiPdIBTwp7E3FJc9bOONtWYzOVcChbIJ3eRfW3w'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f9716fb2-4113-11ea-a3f1-0ef51f60f757', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ddbd37', 'id': '1k56mio', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Overall_Ad_7178', 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k56mio/1000_python_exercises/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k56mio/1000_python_exercises/', 'subreddit_subscribers': 1349732, 'created_utc': 1745329364.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '# üìÅ `lsoph`\\n\\nTUI that lists open files for a given process. Uses `strace` by default, but also `psutil` and `lsof` so will sort-of-work on Mac and Windows too.\\n\\nUsage:\\n\\n```shell\\nuvx pip install lsoph\\nlsoph -p &lt;pid&gt;\\n```\\n\\n# [üé¨ Demo Video](https://asciinema.org/a/c7T8id39jU7ap6E0D99S5dJ6F)\\n\\nProject links:\\n\\n* [üè† home](https://bitplane.net/dev/python/lsoph)\\n* [üê± github](https://github.com/bitplane/lsoph)\\n* [üêç pypi](https://pypi.org/project/lsoph)\\n\\n\\n## Why?\\n\\nBecause I often use `strace` or `lsof` with `grep` to figure out what a program is doing, what files it\\'s opening etc. It\\'s easier than looking for config files. But it gets old fast, what I really want is a list of files for a tree of processes, with the last touched one at the top, so I can see what it\\'s trying to do. And I wan to filter out ones I don\\'t care about. And I want this in a tmux panel too.\\n\\nSo, I\\'d heard good things about Gemini 2.5 Pro, and figured it\\'d only take a couple of hours. So I decided to create it as GenAI slop experiment.\\n\\nThis descended into madness over the course of a weekend, with input from ChatGPT and Claude to keep things moving.\\n\\n**I do not recommend this. Pure AI driven coding is not ready for prime-time**.\\n\\nVibe coders, I never realised how bad you have it!\\n\\n## retro\\n\\nHere\\'s some notes on the 3 robo-chummers who helped me, and what they smell like:\\n\\n### Gemini 2.5 Pro\\n\\n* ‚òï Writes more code than a Java consultancy that\\'s paid by LoC.\\n* ü§° Defends against every type of exception, even import errors; belt,\\n  braces and elasticated waist.\\n* üëñ Its trousers still fall down.\\n* üß± Hard codes special cases and unreachable logic.\\n* üî• Will put verbose debug logging in your hottest loops.\\n* üóë Starts at the complexity ceiling, and manages to climb higher with\\n  every change.\\n* ‚úÖ It needs to be BEST CORRECT, with the pig-headed stubbornness of\\n  `class UnwaveringPigsHead(basemodel)`.\\n* üñï Leaves passive aggressive comments in your code if you abuse it enough,\\n  and doesn\\'t like to tidy up.\\n* ü™¶ It can\\'t write test cases, or testable code.\\n* üí£ Carried by an enormous context window and rapid generation speed,\\n  then the wheels come off.\\n\\n### GPT 4o and 4.5\\n\\n* üí© Can\\'t take the volume of dogshit produced by Gemini (but to be fair who\\n  can?)\\n* üí§ Gets lazy because it\\'s got no context window left, or because Sama is\\n  saving all his GPUs. Probably both.\\n* ü•± Attention slips, it forgets where its up to and then hallucinates all\\n  the details.\\n* ü§• Sycophantmaxxer, but still ignores your requests.\\n* üéâ Can actually write unit tests.\\n* üö¨ Has actually stopped being such an aggressively \"safety focused\" PR\\n  bellend.\\n* üòé A classic case of being down with the kids, a move that\\'s absolute chefs\\n  kiss.\\n\\n### Claude 3.7\\n\\n* ü´ó It has none of the tools that GPT has, none of the mental models that\\n  Gemini has.\\n* üöΩ Still pisses all over them from a great height.\\n* üíá Decent eye for aesthetics.\\n* ü™ü Has a better window size than GPT, and can focus attention better too.\\n* üëâ Mostly does as its told.\\n* üí© Still can\\'t write good code.\\n* ü§ì No banter game whatsoever.\\n\\n## Summary\\n\\nIn the kingdom of the token generators, the one-eyed Claude is king.\\n\\n## License\\n\\nWTFPL with one additional clause:\\n\\n* ‚õî DON\\'T BLAME ME\\n\\n\\n# üí© AutoMod filter\\n\\n## What My Project Does\\n\\nread the title\\n\\n## Target Audience\\n\\npeople like me, on linux\\n\\n## Comparison\\n\\nIf there were alternatives then I wouldn\\'t have made it ü§∑', 'author_fullname': 't2_lr7xph3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'lsoph - a TUI for viewing file access by a process', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5kj23', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 14, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 14, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745363707.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;üìÅ &lt;code&gt;lsoph&lt;/code&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;TUI that lists open files for a given process. Uses &lt;code&gt;strace&lt;/code&gt; by default, but also &lt;code&gt;psutil&lt;/code&gt; and &lt;code&gt;lsof&lt;/code&gt; so will sort-of-work on Mac and Windows too.&lt;/p&gt;\\n\\n&lt;p&gt;Usage:&lt;/p&gt;\\n\\n&lt;p&gt;&lt;code&gt;shell\\nuvx pip install lsoph\\nlsoph -p &amp;lt;pid&amp;gt;\\n&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;h1&gt;&lt;a href=\"https://asciinema.org/a/c7T8id39jU7ap6E0D99S5dJ6F\"&gt;üé¨ Demo Video&lt;/a&gt;&lt;/h1&gt;\\n\\n&lt;p&gt;Project links:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;a href=\"https://bitplane.net/dev/python/lsoph\"&gt;üè† home&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\"https://github.com/bitplane/lsoph\"&gt;üê± github&lt;/a&gt;&lt;/li&gt;\\n&lt;li&gt;&lt;a href=\"https://pypi.org/project/lsoph\"&gt;üêç pypi&lt;/a&gt;&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h2&gt;Why?&lt;/h2&gt;\\n\\n&lt;p&gt;Because I often use &lt;code&gt;strace&lt;/code&gt; or &lt;code&gt;lsof&lt;/code&gt; with &lt;code&gt;grep&lt;/code&gt; to figure out what a program is doing, what files it&amp;#39;s opening etc. It&amp;#39;s easier than looking for config files. But it gets old fast, what I really want is a list of files for a tree of processes, with the last touched one at the top, so I can see what it&amp;#39;s trying to do. And I wan to filter out ones I don&amp;#39;t care about. And I want this in a tmux panel too.&lt;/p&gt;\\n\\n&lt;p&gt;So, I&amp;#39;d heard good things about Gemini 2.5 Pro, and figured it&amp;#39;d only take a couple of hours. So I decided to create it as GenAI slop experiment.&lt;/p&gt;\\n\\n&lt;p&gt;This descended into madness over the course of a weekend, with input from ChatGPT and Claude to keep things moving.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;I do not recommend this. Pure AI driven coding is not ready for prime-time&lt;/strong&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;Vibe coders, I never realised how bad you have it!&lt;/p&gt;\\n\\n&lt;h2&gt;retro&lt;/h2&gt;\\n\\n&lt;p&gt;Here&amp;#39;s some notes on the 3 robo-chummers who helped me, and what they smell like:&lt;/p&gt;\\n\\n&lt;h3&gt;Gemini 2.5 Pro&lt;/h3&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;‚òï Writes more code than a Java consultancy that&amp;#39;s paid by LoC.&lt;/li&gt;\\n&lt;li&gt;ü§° Defends against every type of exception, even import errors; belt,\\nbraces and elasticated waist.&lt;/li&gt;\\n&lt;li&gt;üëñ Its trousers still fall down.&lt;/li&gt;\\n&lt;li&gt;üß± Hard codes special cases and unreachable logic.&lt;/li&gt;\\n&lt;li&gt;üî• Will put verbose debug logging in your hottest loops.&lt;/li&gt;\\n&lt;li&gt;üóë Starts at the complexity ceiling, and manages to climb higher with\\nevery change.&lt;/li&gt;\\n&lt;li&gt;‚úÖ It needs to be BEST CORRECT, with the pig-headed stubbornness of\\n&lt;code&gt;class UnwaveringPigsHead(basemodel)&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;üñï Leaves passive aggressive comments in your code if you abuse it enough,\\nand doesn&amp;#39;t like to tidy up.&lt;/li&gt;\\n&lt;li&gt;ü™¶ It can&amp;#39;t write test cases, or testable code.&lt;/li&gt;\\n&lt;li&gt;üí£ Carried by an enormous context window and rapid generation speed,\\nthen the wheels come off.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h3&gt;GPT 4o and 4.5&lt;/h3&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;üí© Can&amp;#39;t take the volume of dogshit produced by Gemini (but to be fair who\\ncan?)&lt;/li&gt;\\n&lt;li&gt;üí§ Gets lazy because it&amp;#39;s got no context window left, or because Sama is\\nsaving all his GPUs. Probably both.&lt;/li&gt;\\n&lt;li&gt;ü•± Attention slips, it forgets where its up to and then hallucinates all\\nthe details.&lt;/li&gt;\\n&lt;li&gt;ü§• Sycophantmaxxer, but still ignores your requests.&lt;/li&gt;\\n&lt;li&gt;üéâ Can actually write unit tests.&lt;/li&gt;\\n&lt;li&gt;üö¨ Has actually stopped being such an aggressively &amp;quot;safety focused&amp;quot; PR\\nbellend.&lt;/li&gt;\\n&lt;li&gt;üòé A classic case of being down with the kids, a move that&amp;#39;s absolute chefs\\nkiss.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h3&gt;Claude 3.7&lt;/h3&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;ü´ó It has none of the tools that GPT has, none of the mental models that\\nGemini has.&lt;/li&gt;\\n&lt;li&gt;üöΩ Still pisses all over them from a great height.&lt;/li&gt;\\n&lt;li&gt;üíá Decent eye for aesthetics.&lt;/li&gt;\\n&lt;li&gt;ü™ü Has a better window size than GPT, and can focus attention better too.&lt;/li&gt;\\n&lt;li&gt;üëâ Mostly does as its told.&lt;/li&gt;\\n&lt;li&gt;üí© Still can&amp;#39;t write good code.&lt;/li&gt;\\n&lt;li&gt;ü§ì No banter game whatsoever.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h2&gt;Summary&lt;/h2&gt;\\n\\n&lt;p&gt;In the kingdom of the token generators, the one-eyed Claude is king.&lt;/p&gt;\\n\\n&lt;h2&gt;License&lt;/h2&gt;\\n\\n&lt;p&gt;WTFPL with one additional clause:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;‚õî DON&amp;#39;T BLAME ME&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h1&gt;üí© AutoMod filter&lt;/h1&gt;\\n\\n&lt;h2&gt;What My Project Does&lt;/h2&gt;\\n\\n&lt;p&gt;read the title&lt;/p&gt;\\n\\n&lt;h2&gt;Target Audience&lt;/h2&gt;\\n\\n&lt;p&gt;people like me, on linux&lt;/p&gt;\\n\\n&lt;h2&gt;Comparison&lt;/h2&gt;\\n\\n&lt;p&gt;If there were alternatives then I wouldn&amp;#39;t have made it ü§∑&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?auto=webp&amp;s=59c8e92f344625de35172eed636d567293cfac39', 'width': 3083, 'height': 1643}, 'resolutions': [{'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd5c0f728fecb271cb7aaae993b4a389b8107983', 'width': 108, 'height': 57}, {'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb3b3553baef461e54df9af024fc68fd423e0261', 'width': 216, 'height': 115}, {'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b1ada8737a07af2d5e75b7c517962bfedfe07054', 'width': 320, 'height': 170}, {'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=16ff9cbe11b7355466ea649d1f0f8bce44696b98', 'width': 640, 'height': 341}, {'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e88e0cc06108e75e33b2b445f2aa6e0ff7d913f1', 'width': 960, 'height': 511}, {'url': 'https://external-preview.redd.it/BADcgtO--158T04n4qp2XnTtvpoXUAq38kPLuYZXvoE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e17b13def9351ff0f44cc4f5704133f23adb3054', 'width': 1080, 'height': 575}], 'variants': {}, 'id': '_pXzq_Jt1LGgLClDunwdZn_fdbuoCdQ8a7wDzlNlNKg'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k5kj23', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'david-song', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5kj23/lsoph_a_tui_for_viewing_file_access_by_a_process/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5kj23/lsoph_a_tui_for_viewing_file_access_by_a_process/', 'subreddit_subscribers': 1349732, 'created_utc': 1745363707.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '**What My Project Does**\\n\\n**faceit-python** is a high-level, fully type-safe Python wrapper for the [FACEIT REST API](https://docs.faceit.com/docs/). It supports both synchronous and asynchronous clients, strict type checking (mypy-friendly), Pydantic-based models, and handy utilities for pagination and data access.\\n\\n**Target Audience**\\n\\n* Developers who need deep integration with the FACEIT API for analytics, bots, automation, or production services.\\n* The project is under active development, so while it‚Äôs usable for many tasks, caution is advised before using it in production.\\n\\n**Comparison**\\n\\n* **Strict typing:** Full support for type hints and mypy.\\n* **Sync &amp; async interfaces:** Choose whichever style fits your project.\\n* **Modern models:** All data is modeled with Pydantic for easy validation and autocompletion.\\n* **Convenient pagination:** Methods like `.map()`, `.filter()`, and `.find()` are available on paginated results.\\n\\nCompared to existing libraries, **faceit-python** focuses on modern Python, strict typing, and high code quality.\\n\\n**GitHub:** [https://github.com/zombyacoff/faceit-python](https://github.com/zombyacoff/faceit-python)\\n\\nFeedback, questions, and contributions are very welcome!', 'author_fullname': 't2_ufn5jx9h', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'faceit-python: Strongly Typed Python Client for the FACEIT API', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5idmt', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.94, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 22, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 22, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1745406218.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745357971.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;What My Project Does&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;faceit-python&lt;/strong&gt; is a high-level, fully type-safe Python wrapper for the &lt;a href=\"https://docs.faceit.com/docs/\"&gt;FACEIT REST API&lt;/a&gt;. It supports both synchronous and asynchronous clients, strict type checking (mypy-friendly), Pydantic-based models, and handy utilities for pagination and data access.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Target Audience&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Developers who need deep integration with the FACEIT API for analytics, bots, automation, or production services.&lt;/li&gt;\\n&lt;li&gt;The project is under active development, so while it‚Äôs usable for many tasks, caution is advised before using it in production.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Comparison&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;&lt;strong&gt;Strict typing:&lt;/strong&gt; Full support for type hints and mypy.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Sync &amp;amp; async interfaces:&lt;/strong&gt; Choose whichever style fits your project.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Modern models:&lt;/strong&gt; All data is modeled with Pydantic for easy validation and autocompletion.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Convenient pagination:&lt;/strong&gt; Methods like &lt;code&gt;.map()&lt;/code&gt;, &lt;code&gt;.filter()&lt;/code&gt;, and &lt;code&gt;.find()&lt;/code&gt; are available on paginated results.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Compared to existing libraries, &lt;strong&gt;faceit-python&lt;/strong&gt; focuses on modern Python, strict typing, and high code quality.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;GitHub:&lt;/strong&gt; &lt;a href=\"https://github.com/zombyacoff/faceit-python\"&gt;https://github.com/zombyacoff/faceit-python&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Feedback, questions, and contributions are very welcome!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?auto=webp&amp;s=c9f576319ecceddf4c01d02d7fd5dd84b664a0e1', 'width': 1186, 'height': 596}, 'resolutions': [{'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d23d21b89a739e7d5568c38d1f9014f03d6162cc', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4d5c6c4f217619abd7026b3c3d4dc7b2cc0e1b2', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f34e7a92108883a1113fcbe6bebb60e2f7ae4276', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=38ad2ce65bf63380c938a16d0b6ec46d71ad7e73', 'width': 640, 'height': 321}, {'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=48332b7b958be943ddda568a386e1987026bd987', 'width': 960, 'height': 482}, {'url': 'https://external-preview.redd.it/UGVQQuA64hWcZO8rxmF4zw8xE9KG7nDdKsGrh34vc8c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5bb28e66dca94642c612c8b6444bab9642771154', 'width': 1080, 'height': 542}], 'variants': {}, 'id': '4OhWoTVR0cQqnw8T8nqAWBVPIsrfrTgePNJT34BsNXM'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k5idmt', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'GiraffeLarge9085', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5idmt/faceitpython_strongly_typed_python_client_for_the/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5idmt/faceitpython_strongly_typed_python_client_for_the/', 'subreddit_subscribers': 1349732, 'created_utc': 1745357971.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'I was on itch looking for engines and found an engine. It has 3d and customizable. Working on a game. This engine is Infinit Engine.', 'author_fullname': 't2_1ny3z0gvaq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Bought this Engine and love this', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k6f25r', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.13, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745454913.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was on itch looking for engines and found an engine. It has 3d and customizable. Working on a game. This engine is Infinit Engine.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k6f25r', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Competitive_Tower698', 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k6f25r/bought_this_engine_and_love_this/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k6f25r/bought_this_engine_and_love_this/', 'subreddit_subscribers': 1349732, 'created_utc': 1745454913.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'My employer has offered to pay for me to take a python course on company time but has requested that I pick the course myself.\\n\\nIt needs to be self paced so I can work around it without having to worry about set deadlines. Having a bit of a hard time finding courses that meet that requirement.\\n\\nAnyone have suggestions or experience with good courses that fit the bill?', 'author_fullname': 't2_20y86esq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Work offering to pay for a python course. Any recommendations on courses?', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5awlb', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 24, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 24, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745339939.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My employer has offered to pay for me to take a python course on company time but has requested that I pick the course myself.&lt;/p&gt;\\n\\n&lt;p&gt;It needs to be self paced so I can work around it without having to worry about set deadlines. Having a bit of a hard time finding courses that meet that requirement.&lt;/p&gt;\\n\\n&lt;p&gt;Anyone have suggestions or experience with good courses that fit the bill?&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k5awlb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Underbark', 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5awlb/work_offering_to_pay_for_a_python_course_any/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5awlb/work_offering_to_pay_for_a_python_course_any/', 'subreddit_subscribers': 1349732, 'created_utc': 1745339939.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"Hi!\\n\\nI‚Äôve been working on [FastAPI Forge](https://github.com/mslaursen/fastapi-forge) ‚Äî a tool that lets you visually design your FastAPI (a modern web framework written in Python)  backend through a browser-based UI. You can define your database models, select optional services like authentication or caching etc., and then generate a complete project based on your input.\\n\\nThe project is pip-installable, so you can easily get started:\\n\\n    pip install fastapi-forge\\n    fastapi-forge start   # Opens up the UI in your browser\\n\\nIt comes with additional features like saving your project in  YAML, which can then be loaded again using the CLI, and also the ability to reverse-engineer and existing Postgres database by providing a connection string, which FastAPI Forge will then introspect and load into the UI.\\n\\n**What My Project Does**\\n\\n* Visual UI (NiceGUI) for designing database models (tables, relationships, indexes)\\n* Generates complete projects with SQLAlchemy models, Pydantic schemas, CRUD endpoints, DAOs, tests\\n* Adds optional services (Auth, message queues, caching etc.) with checkboxes\\n* Can reverse-engineer APIs from existing Postgres databases\\n* Export /  Import project configuration to / from YAML.\\n* Sets up Github actions for running tests and linters (ruff)\\n* Outputs a fully functional, tested, containerized project, with a competent structure, ready to go with Docker Compose\\n\\nEverything is generated based on your model definitions and config, so you skip all the repetitive boilerplate and get a clean, organized, working codebase.\\n\\n**Target Audience**\\n\\nThis is for developers who:\\n\\n* Need to spin up new FastAPI projects fast  / Create a prototype\\n* Don't want to think about how to structure a FastAPI project\\n* Work with databases and need SQLAlchemy + Pydantic integration\\n* Want plug-and-play extras like auth, message queues, caching etc.\\n* Need to scaffold APIs from existing Postgres databases\\n\\n**Comparison**\\n\\nThere are many FastAPI templates, but this project goes the extra mile of letting you visually design your database models and project configuration, which then translates into working code.\\n\\n**Code**\\n\\nüîó [GitHub ‚Äì FastAPI Forge](https://github.com/mslaursen/fastapi-forge)\\n\\n**Feedback Welcome üôè**\\n\\nWould love your feedback, ideas, or feature requests. I am currently working on adding many more optional service integrations, that users might use. Thanks for checking it out!\", 'author_fullname': 't2_eczpab8zv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'FastAPI Forge: Visually Design &amp; Generate Full FastAPI Backends', 'link_flair_richtext': [{'e': 'text', 't': 'Showcase'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'showcase', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k52709', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 71, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 71, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745314482.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\\n\\n&lt;p&gt;I‚Äôve been working on &lt;a href=\"https://github.com/mslaursen/fastapi-forge\"&gt;FastAPI Forge&lt;/a&gt; ‚Äî a tool that lets you visually design your FastAPI (a modern web framework written in Python)  backend through a browser-based UI. You can define your database models, select optional services like authentication or caching etc., and then generate a complete project based on your input.&lt;/p&gt;\\n\\n&lt;p&gt;The project is pip-installable, so you can easily get started:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;pip install fastapi-forge\\nfastapi-forge start   # Opens up the UI in your browser\\n&lt;/code&gt;&lt;/pre&gt;\\n\\n&lt;p&gt;It comes with additional features like saving your project in  YAML, which can then be loaded again using the CLI, and also the ability to reverse-engineer and existing Postgres database by providing a connection string, which FastAPI Forge will then introspect and load into the UI.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;What My Project Does&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Visual UI (NiceGUI) for designing database models (tables, relationships, indexes)&lt;/li&gt;\\n&lt;li&gt;Generates complete projects with SQLAlchemy models, Pydantic schemas, CRUD endpoints, DAOs, tests&lt;/li&gt;\\n&lt;li&gt;Adds optional services (Auth, message queues, caching etc.) with checkboxes&lt;/li&gt;\\n&lt;li&gt;Can reverse-engineer APIs from existing Postgres databases&lt;/li&gt;\\n&lt;li&gt;Export /  Import project configuration to / from YAML.&lt;/li&gt;\\n&lt;li&gt;Sets up Github actions for running tests and linters (ruff)&lt;/li&gt;\\n&lt;li&gt;Outputs a fully functional, tested, containerized project, with a competent structure, ready to go with Docker Compose&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;Everything is generated based on your model definitions and config, so you skip all the repetitive boilerplate and get a clean, organized, working codebase.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Target Audience&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This is for developers who:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Need to spin up new FastAPI projects fast  / Create a prototype&lt;/li&gt;\\n&lt;li&gt;Don&amp;#39;t want to think about how to structure a FastAPI project&lt;/li&gt;\\n&lt;li&gt;Work with databases and need SQLAlchemy + Pydantic integration&lt;/li&gt;\\n&lt;li&gt;Want plug-and-play extras like auth, message queues, caching etc.&lt;/li&gt;\\n&lt;li&gt;Need to scaffold APIs from existing Postgres databases&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Comparison&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;There are many FastAPI templates, but this project goes the extra mile of letting you visually design your database models and project configuration, which then translates into working code.&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;üîó &lt;a href=\"https://github.com/mslaursen/fastapi-forge\"&gt;GitHub ‚Äì FastAPI Forge&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Feedback Welcome üôè&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;Would love your feedback, ideas, or feature requests. I am currently working on adding many more optional service integrations, that users might use. Thanks for checking it out!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?auto=webp&amp;s=91f51ff3bb0079b1181ac3903384b50d08101eb7', 'width': 1280, 'height': 640}, 'resolutions': [{'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=95560b4bca8e184deef511654018209576d32678', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=73685b6367f08061f02a64f1b7cf555abbb14f5b', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ba78d3d06d3b36da7abd073074e9eb6ed931b09', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b89e76e1d1aa996ddf0d6d45b1bb0c02c7099069', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=39eaffd38b52cbe084c0e6833f00c3c6613a65d0', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/Y9m0x1f-mhoYAIqh68W2atSaSI-cdpKzBKeeQDRuAyI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec9c70d1b7f86e4e5b9c9637fa5ec15b1992e8d9', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'hYTy5oq89AIorqB3wlG2KSC2duVaWMGu9r-U3WhUn6A'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f35fb004-c1ff-11ee-8305-565bc5d0cc73', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1k52709', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Vast_Ad_7117', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k52709/fastapi_forge_visually_design_generate_full/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k52709/fastapi_forge_visually_design_generate_full/', 'subreddit_subscribers': 1349732, 'created_utc': 1745314482.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': 'Make your Python module faster! Add\\xa0tariffs to delay imports based on author origin. Peak optimization!   \\n[https://github.com/hxu296/tariff](https://github.com/hxu296/tariff)', 'author_fullname': 't2_1ckjmn9kqz', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Make your module faster in benchmarks by using tariffs on competing modules!', 'link_flair_richtext': [{'e': 'text', 't': 'Resource'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'resource', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k4qhdd', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 338, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Resource', 'can_mod_post': False, 'score': 338, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745274190.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Make your Python module faster! Add\\xa0tariffs to delay imports based on author origin. Peak optimization!&lt;br/&gt;\\n&lt;a href=\"https://github.com/hxu296/tariff\"&gt;https://github.com/hxu296/tariff&lt;/a&gt;&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?auto=webp&amp;s=2bab99f1765817c666187a8921f6779c492776c7', 'width': 1200, 'height': 600}, 'resolutions': [{'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb271fe0b2d31eab479cce71c88234ef0869d09b', 'width': 108, 'height': 54}, {'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=da7f6059a95b8635919dea8f9a1ebe62921849fb', 'width': 216, 'height': 108}, {'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c06460ac65d3980275fcfffbeb12f52ee1a9ed9d', 'width': 320, 'height': 160}, {'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f26da53310625bbe199df28db6080d1ce987962c', 'width': 640, 'height': 320}, {'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=26c7696d106ac266cd269e59f75a6c29bc631ee1', 'width': 960, 'height': 480}, {'url': 'https://external-preview.redd.it/6JzIqduX91UUdnacBfOPyawQhf6kIlSneH7tp04m9Yg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=99db90853a1518872817225cb3a7ceeb8cf6ed1c', 'width': 1080, 'height': 540}], 'variants': {}, 'id': 'jdhx6Az-eWWy9L1WsmRyUhwtJK2Ff3pulxaT1Y8SAP0'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f9716fb2-4113-11ea-a3f1-0ef51f60f757', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ddbd37', 'id': '1k4qhdd', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'LetsTacoooo', 'discussion_type': None, 'num_comments': 32, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k4qhdd/make_your_module_faster_in_benchmarks_by_using/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k4qhdd/make_your_module_faster_in_benchmarks_by_using/', 'subreddit_subscribers': 1349732, 'created_utc': 1745274190.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"Hi all! I'm building a React responsive web app and as there are lots of FastAPI boilerplates out there I am looking for one that has the following requirements or is easily extendable to include the following requirements:\\n\\n1. Has user registration &amp; authentication routes\\n2. Ability to communicate with MySQL database (users table for storing users, access table for storing access tokens ex UUID)\\n3. Request validation where I can define which parameters are required for each route and limitations (set by database, ex: VARCHAR(30) for first name on user registration)\\n4. Ability to define routes as authentication required or no authentication required (decorator?)\\n5. Ability to add user levels and have certain routes require different user levels. Users level would be stored in the users table I assume as an int\\n6. Models that can be extendable to the frontend easily\\n\\nAny help would be appreciated! I have gone through many, many boilerplate templates and I can't seem to find one that fits perfectly.\", 'author_fullname': 't2_dcx34', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'FastAPI Boilerplate User Login, User Registration, User Levels, Request Validation, etc.', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k55nbl', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 19, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 19, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745326668.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I&amp;#39;m building a React responsive web app and as there are lots of FastAPI boilerplates out there I am looking for one that has the following requirements or is easily extendable to include the following requirements:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;Has user registration &amp;amp; authentication routes&lt;/li&gt;\\n&lt;li&gt;Ability to communicate with MySQL database (users table for storing users, access table for storing access tokens ex UUID)&lt;/li&gt;\\n&lt;li&gt;Request validation where I can define which parameters are required for each route and limitations (set by database, ex: VARCHAR(30) for first name on user registration)&lt;/li&gt;\\n&lt;li&gt;Ability to define routes as authentication required or no authentication required (decorator?)&lt;/li&gt;\\n&lt;li&gt;Ability to add user levels and have certain routes require different user levels. Users level would be stored in the users table I assume as an int&lt;/li&gt;\\n&lt;li&gt;Models that can be extendable to the frontend easily&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Any help would be appreciated! I have gone through many, many boilerplate templates and I can&amp;#39;t seem to find one that fits perfectly.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k55nbl', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'bakhtiya', 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k55nbl/fastapi_boilerplate_user_login_user_registration/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k55nbl/fastapi_boilerplate_user_login_user_registration/', 'subreddit_subscribers': 1349732, 'created_utc': 1745326668.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': '[Module](https://www.reddit.com/r/pythontips/?f=flair_name%3A%22Module%22)\\n\\nThis code is not giving any error\\n\\nIsn\\'t TypedDict here to restrict the format and datatype of a dictionary?\\n\\nThe code\\n\\n    from typing import TypedDict\\n    class State(TypedDict):\\n    \\xa0 \\xa0 \"\"\"\\n    \\xa0 \\xa0 A class representing the state of a node.\\n    \\xa0 \\xa0 \\n    \\xa0 \\xa0 Attributes:\\n    \\xa0 \\xa0 \\xa0 \\xa0graph_state(str)\\n    \\xa0 \\xa0 \"\"\"\\n    \\xa0 \\xa0 graph_state: str \\n    \\n    p1:State={\"graph_state\":1234,\"hello\":\"world\"}\\n    print(f\"\"\"{p1[\"graph_state\"]}\"\"\")\\n    State=TypedDict(\"State\",{\"graph_state\":str})\\n    p2:State={\"graph_state\":1234,\"hello\":\"world\"}\\n    print(f\"\"\"{p2[\"graph_state\"]}\"\"\")', 'author_fullname': 't2_1lf7hmjy0s', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'TypedDict type is not giving any error despite using extra keys and using different datatype for a d', 'link_flair_richtext': [{'e': 'text', 't': 'Help'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'help', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5dy6x', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.63, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745347206.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/pythontips/?f=flair_name%3A%22Module%22\"&gt;Module&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;This code is not giving any error&lt;/p&gt;\\n\\n&lt;p&gt;Isn&amp;#39;t TypedDict here to restrict the format and datatype of a dictionary?&lt;/p&gt;\\n\\n&lt;p&gt;The code&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;from typing import TypedDict\\nclass State(TypedDict):\\n\\xa0 \\xa0 &amp;quot;&amp;quot;&amp;quot;\\n\\xa0 \\xa0 A class representing the state of a node.\\n\\xa0 \\xa0 \\n\\xa0 \\xa0 Attributes:\\n\\xa0 \\xa0 \\xa0 \\xa0graph_state(str)\\n\\xa0 \\xa0 &amp;quot;&amp;quot;&amp;quot;\\n\\xa0 \\xa0 graph_state: str \\n\\np1:State={&amp;quot;graph_state&amp;quot;:1234,&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}\\nprint(f&amp;quot;&amp;quot;&amp;quot;{p1[&amp;quot;graph_state&amp;quot;]}&amp;quot;&amp;quot;&amp;quot;)\\nState=TypedDict(&amp;quot;State&amp;quot;,{&amp;quot;graph_state&amp;quot;:str})\\np2:State={&amp;quot;graph_state&amp;quot;:1234,&amp;quot;hello&amp;quot;:&amp;quot;world&amp;quot;}\\nprint(f&amp;quot;&amp;quot;&amp;quot;{p2[&amp;quot;graph_state&amp;quot;]}&amp;quot;&amp;quot;&amp;quot;)\\n&lt;/code&gt;&lt;/pre&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'c685ca8a-4113-11ea-a273-0e02380d75d9', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '1k5dy6x', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Unlikely_Picture205', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5dy6x/typeddict_type_is_not_giving_any_error_despite/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5dy6x/typeddict_type_is_not_giving_any_error_despite/', 'subreddit_subscribers': 1349732, 'created_utc': 1745347206.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"I've come across situations where I've wanted to add mutable objects to sets, for example to remove duplicates from a list, but this isn't possible as mutable objects are considered unhashable by Python. I think it's possible to create a set class in python that can contain mutable objects, but I'm curious if other people would find this useful as well. The fact that I don't see much discussion about this and afaik such a class doesn't exist already makes me think that I might be missing something. I would create this class to work similarly to how normal sets do, but when adding a mutable object, the set would create a deepcopy of the object and hash the deepcopy. That way changing the original object won't affect the object in the set and mess things up. Also, you wouldn't be able to iterate through the objects in the set like you can normally. You can pop objects from the set but this will remove them, like popping from a list. This is because otherwise someone could access and then mutate an object contained in the set, which would mean its data no longer matched its hash. So this kind of set is more restrained than normal sets in this way, however it is still useful for removing duplicates of mutable objects. Anyway just curious if people think this would be useful and why or why not üôÇ\\n\\nEdit: thanks for the responses everyone! While I still think this could be useful in some cases, I realise now that a) just using a list is easy and sufficient if there aren't a lot of items and b) I should just make my objects immutable in the first place if there's no need for them to be mutable\", 'author_fullname': 't2_163b66', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Would a set class that can hold mutable objects be useful?', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k5c8dk', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.6, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1745348808.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745343133.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve come across situations where I&amp;#39;ve wanted to add mutable objects to sets, for example to remove duplicates from a list, but this isn&amp;#39;t possible as mutable objects are considered unhashable by Python. I think it&amp;#39;s possible to create a set class in python that can contain mutable objects, but I&amp;#39;m curious if other people would find this useful as well. The fact that I don&amp;#39;t see much discussion about this and afaik such a class doesn&amp;#39;t exist already makes me think that I might be missing something. I would create this class to work similarly to how normal sets do, but when adding a mutable object, the set would create a deepcopy of the object and hash the deepcopy. That way changing the original object won&amp;#39;t affect the object in the set and mess things up. Also, you wouldn&amp;#39;t be able to iterate through the objects in the set like you can normally. You can pop objects from the set but this will remove them, like popping from a list. This is because otherwise someone could access and then mutate an object contained in the set, which would mean its data no longer matched its hash. So this kind of set is more restrained than normal sets in this way, however it is still useful for removing duplicates of mutable objects. Anyway just curious if people think this would be useful and why or why not üôÇ&lt;/p&gt;\\n\\n&lt;p&gt;Edit: thanks for the responses everyone! While I still think this could be useful in some cases, I realise now that a) just using a list is easy and sufficient if there aren&amp;#39;t a lot of items and b) I should just make my objects immutable in the first place if there&amp;#39;s no need for them to be mutable&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0df42996-1c5e-11ea-b1a0-0e44e1c5b731', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#f50057', 'id': '1k5c8dk', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'butwhydoesreddit', 'discussion_type': None, 'num_comments': 49, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k5c8dk/would_a_set_class_that_can_hold_mutable_objects/', 'stickied': False, 'url': 'https://www.reddit.com/r/Python/comments/1k5c8dk/would_a_set_class_that_can_hold_mutable_objects/', 'subreddit_subscribers': 1349732, 'created_utc': 1745343133.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}], 'before': None}}\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(\"https://oauth.reddit.com/r/python/hot\",\n",
    "                   headers=headers)\n",
    "\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67daf28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:50.547626Z",
     "start_time": "2023-05-07T21:15:50.532624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunday Daily Thread: What's everyone working on this week?\n",
      "Thursday Daily Thread: Python Careers, Courses, and Furthering Education!\n",
      "Dealing with internal chaos due to a new ‚Äúcode efficiency consultant‚Äù that‚Äôs been hired.\n",
      "Visualizing the Lorenz attractor with Python\n",
      "Polars: what is the status of compatibility with other Python packages?\n",
      "Jonq! Your python wrapper for jq thats readable\n",
      "Taming async events: Backend uses for pairwise, filter, debounce, throttle in `reaktiv`\n",
      "Advanced Alchemy 1.0 - A framework agnostic library for SQLAlchemy\n",
      "iFetch v2.0: A Python Tool for Bulk iCloud Drive Downloads\n",
      "Survey: Energy Efficiency in Software Development ‚Äì Just a Side Effect?\n",
      "Goombay: For all your sequence alignment needs\n",
      "Declarative GUI toolkit - Slint 1.11 upgrades Python Bindings to Beta üöÄ\n",
      "HsdPy: A Python Library for Vector Similarity with SIMD Acceleration\n",
      "CPython's optimization for doubly linked lists in deque (amortizes 200% link memory overhead)\n",
      "(Qiskit) - Quantum Scheduler: Optimize Dependent Workflows Using Variational Quantum Algorithms\n",
      "First release of NeXosim-py front-end for discrete-event simulation and spacecraft digital-twinning\n",
      "Can any one suggest me major projects idea for end semester in python full stack?\n",
      "1,000 Python exercises\n",
      "lsoph - a TUI for viewing file access by a process\n",
      "faceit-python: Strongly Typed Python Client for the FACEIT API\n",
      "Bought this Engine and love this\n",
      "Work offering to pay for a python course. Any recommendations on courses?\n",
      "FastAPI Forge: Visually Design &amp; Generate Full FastAPI Backends\n",
      "Make your module faster in benchmarks by using tariffs on competing modules!\n",
      "FastAPI Boilerplate User Login, User Registration, User Levels, Request Validation, etc.\n",
      "TypedDict type is not giving any error despite using extra keys and using different datatype for a d\n",
      "Would a set class that can hold mutable objects be useful?\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the results, printing the titles of each\n",
    "for post in res.json()['data']['children']:\n",
    "    print(post['data']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb83125f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:50.562631Z",
     "start_time": "2023-05-07T21:15:50.548628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approved_at_utc': None,\n",
       " 'subreddit': 'Python',\n",
       " 'selftext': \"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è\\n\\nHello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!\\n\\n## How it Works:\\n\\n1. **Show &amp; Tell**: Share your current projects, completed works, or future ideas.\\n2. **Discuss**: Get feedback, find collaborators, or just chat about your project.\\n3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.\\n\\n## Guidelines:\\n\\n* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.\\n* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.\\n\\n## Example Shares:\\n\\n1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!\\n2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.\\n3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!\\n\\nLet's build and grow together! Share your journey and learn from others. Happy coding! üåü\",\n",
       " 'author_fullname': 't2_6l4z3',\n",
       " 'saved': False,\n",
       " 'mod_reason_title': None,\n",
       " 'gilded': 0,\n",
       " 'clicked': False,\n",
       " 'title': \"Sunday Daily Thread: What's everyone working on this week?\",\n",
       " 'link_flair_richtext': [{'a': ':pythonLogo:',\n",
       "   'e': 'emoji',\n",
       "   'u': 'https://emoji.redditmedia.com/8yxdpg6xxnr71_t5_2qh0y/pythonLogo'},\n",
       "  {'e': 'text', 't': ' Daily Thread'}],\n",
       " 'subreddit_name_prefixed': 'r/Python',\n",
       " 'hidden': False,\n",
       " 'pwls': 6,\n",
       " 'link_flair_css_class': 'daily-thread',\n",
       " 'downs': 0,\n",
       " 'thumbnail_height': None,\n",
       " 'top_awarded_type': None,\n",
       " 'hide_score': False,\n",
       " 'name': 't3_1k39vt8',\n",
       " 'quarantine': False,\n",
       " 'link_flair_text_color': 'light',\n",
       " 'upvote_ratio': 0.57,\n",
       " 'author_flair_background_color': None,\n",
       " 'subreddit_type': 'public',\n",
       " 'ups': 1,\n",
       " 'total_awards_received': 0,\n",
       " 'media_embed': {},\n",
       " 'thumbnail_width': None,\n",
       " 'author_flair_template_id': None,\n",
       " 'is_original_content': False,\n",
       " 'user_reports': [],\n",
       " 'secure_media': None,\n",
       " 'is_reddit_media_domain': False,\n",
       " 'is_meta': False,\n",
       " 'category': None,\n",
       " 'secure_media_embed': {},\n",
       " 'link_flair_text': ':pythonLogo: Daily Thread',\n",
       " 'can_mod_post': False,\n",
       " 'score': 1,\n",
       " 'approved_by': None,\n",
       " 'is_created_from_ads_ui': False,\n",
       " 'author_premium': True,\n",
       " 'thumbnail': 'self',\n",
       " 'edited': False,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'gildings': {},\n",
       " 'content_categories': None,\n",
       " 'is_self': True,\n",
       " 'mod_note': None,\n",
       " 'created': 1745107233.0,\n",
       " 'link_flair_type': 'richtext',\n",
       " 'wls': 6,\n",
       " 'removed_by_category': None,\n",
       " 'banned_by': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'domain': 'self.Python',\n",
       " 'allow_live_comments': False,\n",
       " 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Weekly Thread: What&amp;#39;s Everyone Working On This Week? üõ†Ô∏è&lt;/h1&gt;\\n\\n&lt;p&gt;Hello &lt;a href=\"/r/Python\"&gt;/r/Python&lt;/a&gt;! It&amp;#39;s time to share what you&amp;#39;ve been working on! Whether it&amp;#39;s a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you&amp;#39;re up to!&lt;/p&gt;\\n\\n&lt;h2&gt;How it Works:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Show &amp;amp; Tell&lt;/strong&gt;: Share your current projects, completed works, or future ideas.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Discuss&lt;/strong&gt;: Get feedback, find collaborators, or just chat about your project.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Inspire&lt;/strong&gt;: Your project might inspire someone else, just as you might get inspired here.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;h2&gt;Guidelines:&lt;/h2&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Feel free to include as many details as you&amp;#39;d like. Code snippets, screenshots, and links are all welcome.&lt;/li&gt;\\n&lt;li&gt;Whether it&amp;#39;s your job, your hobby, or your passion project, all Python-related work is welcome here.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h2&gt;Example Shares:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Machine Learning Model&lt;/strong&gt;: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Web Scraping&lt;/strong&gt;: Built a script to scrape and analyze news articles. It&amp;#39;s helped me understand media bias better.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Automation&lt;/strong&gt;: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Let&amp;#39;s build and grow together! Share your journey and learn from others. Happy coding! üåü&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       " 'likes': None,\n",
       " 'suggested_sort': None,\n",
       " 'banned_at_utc': None,\n",
       " 'view_count': None,\n",
       " 'archived': False,\n",
       " 'no_follow': False,\n",
       " 'is_crosspostable': True,\n",
       " 'pinned': False,\n",
       " 'over_18': False,\n",
       " 'all_awardings': [],\n",
       " 'awarders': [],\n",
       " 'media_only': False,\n",
       " 'link_flair_template_id': '6c024934-de3f-11ea-a05a-0ea86b2be9a1',\n",
       " 'can_gild': False,\n",
       " 'spoiler': False,\n",
       " 'locked': False,\n",
       " 'author_flair_text': None,\n",
       " 'treatment_tags': [],\n",
       " 'visited': False,\n",
       " 'removed_by': None,\n",
       " 'num_reports': None,\n",
       " 'distinguished': 'moderator',\n",
       " 'subreddit_id': 't5_2qh0y',\n",
       " 'author_is_blocked': False,\n",
       " 'mod_reason_by': None,\n",
       " 'removal_reason': None,\n",
       " 'link_flair_background_color': '#00a6a5',\n",
       " 'id': '1k39vt8',\n",
       " 'is_robot_indexable': True,\n",
       " 'report_reasons': None,\n",
       " 'author': 'AutoModerator',\n",
       " 'discussion_type': None,\n",
       " 'num_comments': 0,\n",
       " 'send_replies': False,\n",
       " 'contest_mode': False,\n",
       " 'mod_reports': [],\n",
       " 'author_patreon_flair': False,\n",
       " 'author_flair_text_color': None,\n",
       " 'permalink': '/r/Python/comments/1k39vt8/sunday_daily_thread_whats_everyone_working_on/',\n",
       " 'stickied': True,\n",
       " 'url': 'https://www.reddit.com/r/Python/comments/1k39vt8/sunday_daily_thread_whats_everyone_working_on/',\n",
       " 'subreddit_subscribers': 1349732,\n",
       " 'created_utc': 1745107233.0,\n",
       " 'num_crossposts': 0,\n",
       " 'media': None,\n",
       " 'is_video': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()['data']['children'][0]['data']\n",
    "#data from first post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fed241",
   "metadata": {},
   "source": [
    "Note that you can see what the html looks by putting it in a markdown cell  \n",
    "This first one will parse the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d936f0cf-241c-44ad-8941-aee9ab6f00a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1k39vt8\n"
     ]
    }
   ],
   "source": [
    "print(res.json()['data']['children'][0]['data']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a493a364-f8a7-4371-a084-7cc87dfa5927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(\"https://oauth.reddit.com/r/python/comments/1k39vt8\",\n",
    "                   headers=headers)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55dc86-8d91-4ba8-8c06-83f3f1d838cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa1391f-2940-452e-b264-1124b8c47d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b247b16-936e-46e1-b66a-76559ae38d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba46dcb-6587-4abf-88ba-3d6b105fa9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50a474a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:50.578633Z",
     "start_time": "2023-05-07T21:15:50.564630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Weekly Thread: What&amp;#39;s Everyone Working On This Week? üõ†Ô∏è&lt;/h1&gt;\n",
      "\n",
      "&lt;p&gt;Hello &lt;a href=\"/r/Python\"&gt;/r/Python&lt;/a&gt;! It&amp;#39;s time to share what you&amp;#39;ve been working on! Whether it&amp;#39;s a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you&amp;#39;re up to!&lt;/p&gt;\n",
      "\n",
      "&lt;h2&gt;How it Works:&lt;/h2&gt;\n",
      "\n",
      "&lt;ol&gt;\n",
      "&lt;li&gt;&lt;strong&gt;Show &amp;amp; Tell&lt;/strong&gt;: Share your current projects, completed works, or future ideas.&lt;/li&gt;\n",
      "&lt;li&gt;&lt;strong&gt;Discuss&lt;/strong&gt;: Get feedback, find collaborators, or just chat about your project.&lt;/li&gt;\n",
      "&lt;li&gt;&lt;strong&gt;Inspire&lt;/strong&gt;: Your project might inspire someone else, just as you might get inspired here.&lt;/li&gt;\n",
      "&lt;/ol&gt;\n",
      "\n",
      "&lt;h2&gt;Guidelines:&lt;/h2&gt;\n",
      "\n",
      "&lt;ul&gt;\n",
      "&lt;li&gt;Feel free to include as many details as you&amp;#39;d like. Code snippets, screenshots, and links are all welcome.&lt;/li&gt;\n",
      "&lt;li&gt;Whether it&amp;#39;s your job, your hobby, or your passion project, all Python-related work is welcome here.&lt;/li&gt;\n",
      "&lt;/ul&gt;\n",
      "\n",
      "&lt;h2&gt;Example Shares:&lt;/h2&gt;\n",
      "\n",
      "&lt;ol&gt;\n",
      "&lt;li&gt;&lt;strong&gt;Machine Learning Model&lt;/strong&gt;: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!&lt;/li&gt;\n",
      "&lt;li&gt;&lt;strong&gt;Web Scraping&lt;/strong&gt;: Built a script to scrape and analyze news articles. It&amp;#39;s helped me understand media bias better.&lt;/li&gt;\n",
      "&lt;li&gt;&lt;strong&gt;Automation&lt;/strong&gt;: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!&lt;/li&gt;\n",
      "&lt;/ol&gt;\n",
      "\n",
      "&lt;p&gt;Let&amp;#39;s build and grow together! Share your journey and learn from others. Happy coding! üåü&lt;/p&gt;\n",
      "&lt;/div&gt;&lt;!-- SC_ON --&gt;\n"
     ]
    }
   ],
   "source": [
    "print(res.json()['data']['children'][0]['data']['selftext_html'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f32ef",
   "metadata": {},
   "source": [
    "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tell &lt;a href=\"/r/python\"&gt;/r/python&lt;/a&gt; what you&amp;#39;re working on this week! You can be bragging, grousing, sharing your passion, or explaining your pain. Talk about your current project or your pet project; whatever you want to share.&lt;/p&gt;\n",
    "&lt;/div&gt;&lt;!-- SC_ON --&gt;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97167fec",
   "metadata": {},
   "source": [
    "This second one will then parse the html:  \n",
    "<!-- SC_OFF --><div class=\"md\"><p>Tell <a href=\"/r/python\">/r/python</a> what you&#39;re working on this week! You can be bragging, grousing, sharing your passion, or explaining your pain. Talk about your current project or your pet project; whatever you want to share.</p> </div><!-- SC_ON -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1affb",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "**In the following example, I am limiting the results to 1 and then requesting more. This is purely a demonstration. DO NOT do this for real unless your limit is set to 100, as this would otherwise count as abuse of Reddit's API.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873c788-055d-4427-8a5a-5bdf9bf2c3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e2ef4b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T21:15:51.260609Z",
     "start_time": "2023-05-07T21:15:50.579634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "How should I teach someone coming from Stata?\n",
      "1k6unrd\n",
      "1\n",
      "Taming async events: Backend uses for pairwise, filter, debounce, throttle in `reaktiv`\n",
      "1k6relk\n",
      "1\n",
      "Polars: what is the status of compatibility with other Python packages?\n",
      "1k6ppc7\n"
     ]
    }
   ],
   "source": [
    "# Tell the API to only return 1 result\n",
    "params = {'limit': 1}\n",
    "\n",
    "for i in range(3):\n",
    "    res = requests.get(\n",
    "        \"https://oauth.reddit.com/r/python/new\",\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    )\n",
    "    \n",
    "    post = res.json()['data']['children'][0]\n",
    "    print(len(res.json()['data']['children']))\n",
    "    print(post['data']['title'])\n",
    "    print(post['data']['id'])\n",
    "    # This is how the API identifies the post we just got\n",
    "    fullname = f\"{post['kind']}_{post['data']['id']}\"\n",
    "    \n",
    "    # This tells the API that the post we want is the one after the current one in the queue (ie is the next oldest one).\n",
    "    params['after'] = fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05af825a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(\"https://oauth.reddit.com/r/python/comments/1k39vt8\",\n",
    "                   headers=headers)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57e924c8-5c66-41a0-8a8a-8a9bca3b75ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.json()[0]['data']['children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b090302c-b19a-4853-9d77-d981650c556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'approved_at_utc': None, 'subreddit': 'Python', 'selftext': \"# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è\\n\\nHello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!\\n\\n## How it Works:\\n\\n1. **Show &amp; Tell**: Share your current projects, completed works, or future ideas.\\n2. **Discuss**: Get feedback, find collaborators, or just chat about your project.\\n3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.\\n\\n## Guidelines:\\n\\n* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.\\n* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.\\n\\n## Example Shares:\\n\\n1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!\\n2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.\\n3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!\\n\\nLet's build and grow together! Share your journey and learn from others. Happy coding! üåü\", 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': \"Sunday Daily Thread: What's everyone working on this week?\", 'link_flair_richtext': [{'a': ':pythonLogo:', 'u': 'https://emoji.redditmedia.com/8yxdpg6xxnr71_t5_2qh0y/pythonLogo', 'e': 'emoji'}, {'e': 'text', 't': ' Daily Thread'}], 'subreddit_name_prefixed': 'r/Python', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'daily-thread', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1k39vt8', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'author_fullname': 't2_6l4z3', 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': ':pythonLogo: Daily Thread', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1745107233.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.Python', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Weekly Thread: What&amp;#39;s Everyone Working On This Week? üõ†Ô∏è&lt;/h1&gt;\\n\\n&lt;p&gt;Hello &lt;a href=\"/r/Python\"&gt;/r/Python&lt;/a&gt;! It&amp;#39;s time to share what you&amp;#39;ve been working on! Whether it&amp;#39;s a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you&amp;#39;re up to!&lt;/p&gt;\\n\\n&lt;h2&gt;How it Works:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Show &amp;amp; Tell&lt;/strong&gt;: Share your current projects, completed works, or future ideas.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Discuss&lt;/strong&gt;: Get feedback, find collaborators, or just chat about your project.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Inspire&lt;/strong&gt;: Your project might inspire someone else, just as you might get inspired here.&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;h2&gt;Guidelines:&lt;/h2&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Feel free to include as many details as you&amp;#39;d like. Code snippets, screenshots, and links are all welcome.&lt;/li&gt;\\n&lt;li&gt;Whether it&amp;#39;s your job, your hobby, or your passion project, all Python-related work is welcome here.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;h2&gt;Example Shares:&lt;/h2&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;strong&gt;Machine Learning Model&lt;/strong&gt;: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Web Scraping&lt;/strong&gt;: Built a script to scrape and analyze news articles. It&amp;#39;s helped me understand media bias better.&lt;/li&gt;\\n&lt;li&gt;&lt;strong&gt;Automation&lt;/strong&gt;: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!&lt;/li&gt;\\n&lt;/ol&gt;\\n\\n&lt;p&gt;Let&amp;#39;s build and grow together! Share your journey and learn from others. Happy coding! üåü&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '6c024934-de3f-11ea-a05a-0ea86b2be9a1', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': 'moderator', 'subreddit_id': 't5_2qh0y', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#00a6a5', 'id': '1k39vt8', 'is_robot_indexable': True, 'num_duplicates': 0, 'report_reasons': None, 'author': 'AutoModerator', 'discussion_type': None, 'num_comments': 0, 'send_replies': False, 'media': None, 'contest_mode': False, 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Python/comments/1k39vt8/sunday_daily_thread_whats_everyone_working_on/', 'stickied': True, 'url': 'https://www.reddit.com/r/Python/comments/1k39vt8/sunday_daily_thread_whats_everyone_working_on/', 'subreddit_subscribers': 1349748, 'created_utc': 1745107233.0, 'num_crossposts': 0, 'mod_reports': [], 'is_video': False}\n"
     ]
    }
   ],
   "source": [
    "for comment in res.json()[0][\"data\"][\"children\"]:\n",
    "    print(comment[\"data\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1f91e-e166-48f6-a76a-161a4d90c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for comment in res.json()[0][\"data\"][\"children\"]:\n",
    " #   print(comment[\"data\"][\"body\"])\n",
    "  #  for reply in comment[\"replies\"][\"data\"][\"children\"]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
